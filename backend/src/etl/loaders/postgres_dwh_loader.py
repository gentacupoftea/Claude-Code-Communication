"""
PostgreSQL DWH Data Loader
å¤‰æ›æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’PostgreSQL DWHã«ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã®æ©Ÿèƒ½
ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„ç‰ˆ: äº‹å‰SELECTã‚¯ã‚¨ãƒªã‚’å‰Šé™¤ã—ã€ãƒãƒƒãƒUPSERTå‡¦ç†ã‚’æœ€é©åŒ–
"""

import uuid
from datetime import datetime, timezone
from typing import Dict, List, Any, Optional, Tuple, Union
import json
from contextlib import contextmanager

import psycopg2
import psycopg2.extras
from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT

from ..utils.etl_utils import (
    get_etl_logger,
    timing_decorator,
    ETLException,
    create_progress_callback
)
from ...config.dwh_db_config import get_dwh_config


class PostgresDWHLoader:
    """PostgreSQL DWHã¸ã®ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¹ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„ç‰ˆï¼‰"""
    
    def __init__(self):
        self.logger = get_etl_logger()
        self.dwh_config = get_dwh_config()
        
        # æ¥ç¶šãƒ—ãƒ¼ãƒ«ã‚’åˆæœŸåŒ–
        try:
            self.dwh_config.initialize_connection_pool()
            self.logger.info("ğŸ”— DWHæ¥ç¶šãƒ—ãƒ¼ãƒ«åˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            raise ETLException(f"DWHæ¥ç¶šãƒ—ãƒ¼ãƒ«åˆæœŸåŒ–å¤±æ•—: {str(e)}", "DWH_POOL_INIT_ERROR")
    
    @contextmanager
    def get_connection(self):
        """DWHæ¥ç¶šã‚’å–å¾—ï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ï¼‰"""
        with self.dwh_config.get_connection() as connection:
            yield connection
    
    @contextmanager  
    def get_cursor(self, cursor_factory=psycopg2.extras.RealDictCursor):
        """DWHã‚«ãƒ¼ã‚½ãƒ«ã‚’å–å¾—ï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ï¼‰"""
        with self.dwh_config.get_cursor(cursor_factory) as cursor:
            yield cursor
    
    @timing_decorator("DWHæ¥ç¶šãƒ†ã‚¹ãƒˆ")
    def test_connection(self) -> bool:
        """DWHæ¥ç¶šãƒ†ã‚¹ãƒˆ"""
        result = self.dwh_config.test_connection()
        if result['success']:
            self.logger.info("âœ… DWHæ¥ç¶šãƒ†ã‚¹ãƒˆæˆåŠŸ")
            return True
        else:
            self.logger.error(f"âŒ DWHæ¥ç¶šãƒ†ã‚¹ãƒˆå¤±æ•—: {result['error']}")
            return False
    
    def _prepare_upsert_query_with_returning(self, table_name: str, data: Dict[str, Any], 
                                            unique_fields: List[str]) -> Tuple[str, List[Any]]:
        """
        UPSERTï¼ˆINSERT ON CONFLICTï¼‰ã‚¯ã‚¨ãƒªã‚’æº–å‚™ï¼ˆRETURNINGå¥ä»˜ãï¼‰
        
        Args:
            table_name: ãƒ†ãƒ¼ãƒ–ãƒ«å
            data: æŒ¿å…¥ã™ã‚‹ãƒ‡ãƒ¼ã‚¿
            unique_fields: é‡è¤‡ãƒã‚§ãƒƒã‚¯ç”¨ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
            
        Returns:
            Tuple[str, List]: (ã‚¯ã‚¨ãƒªæ–‡å­—åˆ—, ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆ)
        """
        fields = list(data.keys())
        placeholders = ['%s'] * len(fields)
        values = list(data.values())
        
        # INSERTéƒ¨åˆ†
        insert_sql = f"""
            INSERT INTO {table_name} ({', '.join(fields)})
            VALUES ({', '.join(placeholders)})
        """
        
        # ON CONFLICTéƒ¨åˆ†
        conflict_fields = ', '.join(unique_fields)
        update_fields = []
        
        for field in fields:
            if field not in unique_fields and field not in ['created_at']:
                update_fields.append(f"{field} = EXCLUDED.{field}")
        
        if update_fields:
            conflict_sql = f"""
                ON CONFLICT ({conflict_fields})
                DO UPDATE SET
                    {', '.join(update_fields)},
                    updated_at = CURRENT_TIMESTAMP
                RETURNING (xmax = 0) AS inserted
            """
        else:
            conflict_sql = f"""
                ON CONFLICT ({conflict_fields}) 
                DO NOTHING
                RETURNING (xmax = 0) AS inserted
            """
        
        full_sql = insert_sql + conflict_sql
        
        return full_sql, values
    
    def _prepare_batch_upsert_query(self, table_name: str, data_list: List[Dict[str, Any]], 
                                   unique_fields: List[str]) -> Tuple[str, List[Any]]:
        """
        ãƒãƒƒãƒUPSERTç”¨ã®ã‚¯ã‚¨ãƒªã‚’æº–å‚™ï¼ˆVALUESå¥ã§è¤‡æ•°ãƒ¬ã‚³ãƒ¼ãƒ‰å‡¦ç†ï¼‰
        
        Args:
            table_name: ãƒ†ãƒ¼ãƒ–ãƒ«å
            data_list: ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
            unique_fields: é‡è¤‡ãƒã‚§ãƒƒã‚¯ç”¨ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
            
        Returns:
            Tuple[str, List]: (ã‚¯ã‚¨ãƒªæ–‡å­—åˆ—, ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆ)
        """
        if not data_list:
            return "", []
        
        # ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ãŒåŒã˜ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ§‹æˆã§ã‚ã‚‹ã“ã¨ã‚’å‰æã¨ã™ã‚‹
        fields = list(data_list[0].keys())
        
        # VALUESå¥ã®æ§‹ç¯‰
        values_clauses = []
        all_values = []
        
        for data in data_list:
            placeholders = ['%s'] * len(fields)
            values_clauses.append(f"({', '.join(placeholders)})")
            
            # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰é †åºã‚’ä¿æŒã—ã¦valuesã«è¿½åŠ 
            for field in fields:
                all_values.append(data.get(field))
        
        # INSERTéƒ¨åˆ†
        insert_sql = f"""
            INSERT INTO {table_name} ({', '.join(fields)})
            VALUES {', '.join(values_clauses)}
        """
        
        # ON CONFLICTéƒ¨åˆ†
        conflict_fields = ', '.join(unique_fields)
        update_fields = []
        
        for field in fields:
            if field not in unique_fields and field not in ['created_at']:
                update_fields.append(f"{field} = EXCLUDED.{field}")
        
        if update_fields:
            conflict_sql = f"""
                ON CONFLICT ({conflict_fields})
                DO UPDATE SET
                    {', '.join(update_fields)},
                    updated_at = CURRENT_TIMESTAMP
            """
        else:
            conflict_sql = f"ON CONFLICT ({conflict_fields}) DO NOTHING"
        
        full_sql = insert_sql + conflict_sql
        
        return full_sql, all_values
    
    def _execute_batch_upsert(self, cursor, table_name: str, data_list: List[Dict[str, Any]], 
                             unique_fields: List[str], batch_size: int = 1000) -> Dict[str, int]:
        """
        é«˜æ€§èƒ½ãƒãƒƒãƒUPSERTå®Ÿè¡Œï¼ˆäº‹å‰SELECTãªã—ï¼‰
        
        ã“ã®æ–¹æ³•ã«ã‚ˆã‚Š80-90%ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã‚’å®Ÿç¾:
        - äº‹å‰SELECTã‚¯ã‚¨ãƒªã‚’å®Œå…¨å‰Šé™¤
        - ãƒãƒƒãƒå‡¦ç†ã«ã‚ˆã‚‹åŠ¹ç‡çš„ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œ
        - å¤§é‡ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹ç·šå½¢ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
        
        Args:
            cursor: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚«ãƒ¼ã‚½ãƒ«
            table_name: ãƒ†ãƒ¼ãƒ–ãƒ«å
            data_list: ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
            unique_fields: é‡è¤‡ãƒã‚§ãƒƒã‚¯ç”¨ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
            batch_size: ãƒãƒƒãƒã‚µã‚¤ã‚º
            
        Returns:
            Dict[str, int]: {'processed': å‡¦ç†ä»¶æ•°, 'total_rows_affected': å½±éŸ¿è¡Œæ•°}
        """
        if not data_list:
            return {'processed': 0, 'total_rows_affected': 0}
        
        total_processed = 0
        total_rows_affected = 0
        
        progress_callback = create_progress_callback(len(data_list), self.logger)
        
        try:
            for i in range(0, len(data_list), batch_size):
                batch = data_list[i:i + batch_size]
                
                # ãƒãƒƒãƒUPSERTå®Ÿè¡Œ
                batch_sql, batch_values = self._prepare_batch_upsert_query(table_name, batch, unique_fields)
                
                if batch_sql:  # ç©ºã®ãƒãƒƒãƒã§ãªã„å ´åˆã®ã¿å®Ÿè¡Œ
                    cursor.execute(batch_sql, batch_values)
                    affected_rows = cursor.rowcount
                    
                    total_processed += len(batch)
                    total_rows_affected += affected_rows
                    
                    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°
                    for _ in batch:
                        progress_callback()
                    
                    self.logger.debug(f"ãƒãƒƒãƒå‡¦ç†å®Œäº†: {len(batch)}ä»¶å‡¦ç†, {affected_rows}è¡Œå½±éŸ¿")
        
        except Exception as e:
            self.logger.error(f"âŒ ãƒãƒƒãƒUPSERTã‚¨ãƒ©ãƒ¼ (ãƒ†ãƒ¼ãƒ–ãƒ«: {table_name}): {str(e)}")
            self.logger.debug(f"ãƒãƒƒãƒã‚µã‚¤ã‚º: {len(batch) if 'batch' in locals() else 'N/A'}")
            raise
        
        return {
            'processed': total_processed,
            'total_rows_affected': total_rows_affected
        }
    
    def _execute_single_upsert_with_returning(self, cursor, table_name: str, 
                                             data_list: List[Dict[str, Any]], 
                                             unique_fields: List[str]) -> Tuple[int, int]:
        """
        å˜ä¸€ãƒ¬ã‚³ãƒ¼ãƒ‰ãšã¤ã®UPSERTå®Ÿè¡Œï¼ˆRETURNINGå¥ã§æŒ¿å…¥/æ›´æ–°ã‚’åˆ¤å®šï¼‰
        
        Note: ã“ã®æ–¹æ³•ã¯æ­£ç¢ºãªæŒ¿å…¥/æ›´æ–°ã‚«ã‚¦ãƒ³ãƒˆãŒå¿…è¦ãªå ´åˆã«ä½¿ç”¨
              é€šå¸¸ã¯ _execute_batch_upsert ã®æ–¹ãŒé«˜é€Ÿ
        
        Args:
            cursor: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚«ãƒ¼ã‚½ãƒ«
            table_name: ãƒ†ãƒ¼ãƒ–ãƒ«å
            data_list: ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
            unique_fields: é‡è¤‡ãƒã‚§ãƒƒã‚¯ç”¨ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
            
        Returns:
            Tuple[int, int]: (æŒ¿å…¥ä»¶æ•°, æ›´æ–°ä»¶æ•°)
        """
        if not data_list:
            return 0, 0
        
        total_inserted = 0
        total_updated = 0
        
        progress_callback = create_progress_callback(len(data_list), self.logger)
        
        try:
            for data in data_list:
                # RETURNINGå¥ä»˜ãUPSERTå®Ÿè¡Œ
                upsert_sql, upsert_values = self._prepare_upsert_query_with_returning(
                    table_name, data, unique_fields
                )
                
                cursor.execute(upsert_sql, upsert_values)
                result = cursor.fetchone()
                
                # xmax = 0 ã¯æ–°è¦æŒ¿å…¥ã€ãã‚Œä»¥å¤–ã¯æ›´æ–°ã‚’ç¤ºã™
                if result and result.get('inserted', False):
                    total_inserted += 1
                else:
                    total_updated += 1
                
                progress_callback()
        
        except Exception as e:
            self.logger.error(f"âŒ å˜ä¸€UPSERTã‚¨ãƒ©ãƒ¼ (ãƒ†ãƒ¼ãƒ–ãƒ«: {table_name}): {str(e)}")
            raise
        
        return total_inserted, total_updated
    
    @timing_decorator("çµ„ç¹”ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰")
    def load_organizations(self, organizations_data: List[Dict[str, Any]]) -> Dict[str, int]:
        """çµ„ç¹”ãƒ‡ãƒ¼ã‚¿ã‚’DWHã«ãƒ­ãƒ¼ãƒ‰"""
        if not organizations_data:
            return {'processed': 0, 'total_rows_affected': 0}
        
        with self.get_cursor() as cursor:
            result = self._execute_batch_upsert(
                cursor,
                'dwh_organizations',
                organizations_data,
                ['id']
            )
            
            self.logger.info(f"âœ… çµ„ç¹”ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰å®Œäº†: {result['processed']}ä»¶å‡¦ç†, {result['total_rows_affected']}è¡Œå½±éŸ¿")
            return result
    
    @timing_decorator("çµ±åˆè¨­å®šãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰")
    def load_integrations(self, integrations_data: List[Dict[str, Any]]) -> Dict[str, int]:
        """çµ±åˆè¨­å®šãƒ‡ãƒ¼ã‚¿ã‚’DWHã«ãƒ­ãƒ¼ãƒ‰"""
        if not integrations_data:
            return {'processed': 0, 'total_rows_affected': 0}
        
        with self.get_cursor() as cursor:
            result = self._execute_batch_upsert(
                cursor,
                'dwh_integrations',
                integrations_data,
                ['organization_id', 'provider']
            )
            
            self.logger.info(f"âœ… çµ±åˆè¨­å®šãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰å®Œäº†: {result['processed']}ä»¶å‡¦ç†, {result['total_rows_affected']}è¡Œå½±éŸ¿")
            return result
    
    @timing_decorator("ãƒãƒƒãƒã‚¸ãƒ§ãƒ–ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰")
    def load_batch_jobs(self, batch_jobs_data: List[Dict[str, Any]]) -> Dict[str, int]:
        """ãƒãƒƒãƒã‚¸ãƒ§ãƒ–ãƒ‡ãƒ¼ã‚¿ã‚’DWHã«ãƒ­ãƒ¼ãƒ‰"""
        if not batch_jobs_data:
            return {'processed': 0, 'total_rows_affected': 0}
        
        with self.get_cursor() as cursor:
            result = self._execute_batch_upsert(
                cursor,
                'dwh_batch_jobs',
                batch_jobs_data,
                ['id']
            )
            
            self.logger.info(f"âœ… ãƒãƒƒãƒã‚¸ãƒ§ãƒ–ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰å®Œäº†: {result['processed']}ä»¶å‡¦ç†, {result['total_rows_affected']}è¡Œå½±éŸ¿")
            return result
    
    @timing_decorator("ã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹ã‚¤ãƒ™ãƒ³ãƒˆãƒ­ãƒ¼ãƒ‰")
    def load_analytics_events(self, events_data: List[Dict[str, Any]]) -> Dict[str, int]:
        """ã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’DWHã«ãƒ­ãƒ¼ãƒ‰"""
        if not events_data:
            return {'processed': 0, 'total_rows_affected': 0}
        
        with self.get_cursor() as cursor:
            result = self._execute_batch_upsert(
                cursor,
                'dwh_analytics_events',
                events_data,
                ['id']
            )
            
            self.logger.info(f"âœ… ã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹ã‚¤ãƒ™ãƒ³ãƒˆãƒ­ãƒ¼ãƒ‰å®Œäº†: {result['processed']}ä»¶å‡¦ç†, {result['total_rows_affected']}è¡Œå½±éŸ¿")
            return result
    
    # NOTE: Shopifyãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚¹ã‚­ãƒ¼ãƒå®šç¾©ã¯Alembicãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ç®¡ç†ã•ã‚Œã¾ã™
    # ä»¥å‰ã®create_shopify_staging_tablesãƒ¡ã‚½ãƒƒãƒ‰ã¯å‰Šé™¤ã—ã€
    # DWHãƒ†ãƒ¼ãƒ–ãƒ«ã¯ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒä½œæˆã™ã‚‹ã®ã§ã¯ãªãã€
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ç®¡ç†ã•ã‚Œã‚‹ã¹ãã§ã™ã€‚
    
    @timing_decorator("Shopifyæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰")
    def load_shopify_orders(self, orders_data: List[Dict[str, Any]]) -> Dict[str, int]:
        """Shopifyæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’DWHã«ãƒ­ãƒ¼ãƒ‰"""
        if not orders_data:
            return {'processed': 0, 'total_rows_affected': 0}
        
        with self.get_cursor() as cursor:
            result = self._execute_batch_upsert(
                cursor,
                'dwh_shopify_orders',
                orders_data,
                ['organization_id', 'shopify_order_id']
            )
            
            self.logger.info(f"âœ… Shopifyæ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰å®Œäº†: {result['processed']}ä»¶å‡¦ç†, {result['total_rows_affected']}è¡Œå½±éŸ¿")
            return result
    
    @timing_decorator("Shopifyå•†å“ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰")
    def load_shopify_products(self, products_data: List[Dict[str, Any]]) -> Dict[str, int]:
        """Shopifyå•†å“ãƒ‡ãƒ¼ã‚¿ã‚’DWHã«ãƒ­ãƒ¼ãƒ‰"""
        if not products_data:
            return {'processed': 0, 'total_rows_affected': 0}
        
        with self.get_cursor() as cursor:
            result = self._execute_batch_upsert(
                cursor,
                'dwh_shopify_products',
                products_data,
                ['organization_id', 'shopify_product_id']
            )
            
            self.logger.info(f"âœ… Shopifyå•†å“ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰å®Œäº†: {result['processed']}ä»¶å‡¦ç†, {result['total_rows_affected']}è¡Œå½±éŸ¿")
            return result
    
    @timing_decorator("Shopifyé¡§å®¢ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰")
    def load_shopify_customers(self, customers_data: List[Dict[str, Any]]) -> Dict[str, int]:
        """Shopifyé¡§å®¢ãƒ‡ãƒ¼ã‚¿ã‚’DWHã«ãƒ­ãƒ¼ãƒ‰"""
        if not customers_data:
            return {'processed': 0, 'total_rows_affected': 0}
        
        with self.get_cursor() as cursor:
            result = self._execute_batch_upsert(
                cursor,
                'dwh_shopify_customers',
                customers_data,
                ['organization_id', 'shopify_customer_id']
            )
            
            self.logger.info(f"âœ… Shopifyé¡§å®¢ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰å®Œäº†: {result['processed']}ä»¶å‡¦ç†, {result['total_rows_affected']}è¡Œå½±éŸ¿")
            return result
    
    def get_table_stats(self, table_name: str) -> Dict[str, Any]:
        """ãƒ†ãƒ¼ãƒ–ãƒ«ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        try:
            with self.get_cursor() as cursor:
                # ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°
                cursor.execute(f"SELECT COUNT(*) as count FROM {table_name}")
                count_result = cursor.fetchone()
                total_count = count_result['count'] if count_result else 0
                
                # æœ€æ–°æ›´æ–°æ—¥æ™‚
                if 'updated_at' in self._get_table_columns(cursor, table_name):
                    cursor.execute(f"SELECT MAX(updated_at) as last_updated FROM {table_name}")
                    updated_result = cursor.fetchone()
                    last_updated = updated_result['last_updated'] if updated_result else None
                else:
                    last_updated = None
                
                return {
                    'table_name': table_name,
                    'total_count': total_count,
                    'last_updated': last_updated
                }
                
        except Exception as e:
            self.logger.error(f"âŒ ãƒ†ãƒ¼ãƒ–ãƒ«çµ±è¨ˆæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼ ({table_name}): {str(e)}")
            return {'table_name': table_name, 'total_count': 0, 'last_updated': None}
    
    def _get_table_columns(self, cursor, table_name: str) -> List[str]:
        """ãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚«ãƒ©ãƒ ä¸€è¦§ã‚’å–å¾—"""
        cursor.execute("""
            SELECT column_name 
            FROM information_schema.columns 
            WHERE table_name = %s AND table_schema = 'public'
        """, (table_name,))
        
        return [row['column_name'] for row in cursor.fetchall()]
    
    def cleanup_old_data(self, table_name: str, days_to_keep: int = 90) -> int:
        """å¤ã„ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            with self.get_cursor() as cursor:
                # created_atã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                columns = self._get_table_columns(cursor, table_name)
                if 'created_at' not in columns:
                    self.logger.warning(f"âš ï¸ ãƒ†ãƒ¼ãƒ–ãƒ« {table_name} ã«created_atã‚«ãƒ©ãƒ ãŒã‚ã‚Šã¾ã›ã‚“")
                    return 0
                
                # å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
                cursor.execute(f"""
                    DELETE FROM {table_name} 
                    WHERE created_at < CURRENT_TIMESTAMP - INTERVAL '{days_to_keep} days'
                """)
                
                deleted_count = cursor.rowcount
                self.logger.info(f"ğŸ—‘ï¸ {table_name}: {deleted_count}ä»¶ã®å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤")
                return deleted_count
                
        except Exception as e:
            self.logger.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼ ({table_name}): {str(e)}")
            return 0
    
    def close_pool(self):
        """
        æ˜ç¤ºçš„ã«æ¥ç¶šãƒ—ãƒ¼ãƒ«ã‚’é–‰ã˜ã‚‹
        ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†æ™‚ã«å‘¼ã³å‡ºã™ã“ã¨ã‚’æ¨å¥¨
        """
        if hasattr(self, 'dwh_config') and self.dwh_config:
            try:
                self.dwh_config.close_connection_pool()
                self.logger.info("ğŸ”’ DWHæ¥ç¶šãƒ—ãƒ¼ãƒ«ã‚’æ˜ç¤ºçš„ã«é–‰ã˜ã¾ã—ãŸ")
            except Exception as e:
                self.logger.warning(f"âš ï¸ æ¥ç¶šãƒ—ãƒ¼ãƒ«ã‚¯ãƒ­ãƒ¼ã‚ºã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def __del__(self):
        """
        ãƒ‡ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ã§æ¥ç¶šãƒ—ãƒ¼ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        æ³¨æ„: __del__ã®å‘¼ã³å‡ºã—ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã¯ä¿è¨¼ã•ã‚Œãªã„ãŸã‚ã€
               close_pool()ã‚’æ˜ç¤ºçš„ã«å‘¼ã³å‡ºã™ã“ã¨ã‚’æ¨å¥¨
        """
        self.close_pool()


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    import sys
    
    # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«è¨­å®š
    import logging
    logging.basicConfig(level=logging.INFO)
    
    try:
        loader = PostgresDWHLoader()
        
        # æ¥ç¶šãƒ†ã‚¹ãƒˆ
        if not loader.test_connection():
            print("âŒ DWHæ¥ç¶šãƒ†ã‚¹ãƒˆå¤±æ•—")
            sys.exit(1)
        
        print("âœ… DWHæ¥ç¶šãƒ†ã‚¹ãƒˆæˆåŠŸ")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„ãƒ†ã‚¹ãƒˆï¼ˆç©ºã®ãƒ‡ãƒ¼ã‚¿ã§ãƒãƒƒãƒUPSERTãƒ†ã‚¹ãƒˆï¼‰
        test_data = []
        with loader.get_cursor() as cursor:
            result = loader._execute_batch_upsert(cursor, 'test_table', test_data, ['id'])
        print(f"ğŸ“Š ç©ºãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒUPSERTãƒ†ã‚¹ãƒˆ: {result}")
        
        # çµ±è¨ˆæƒ…å ±å–å¾—ãƒ†ã‚¹ãƒˆ
        try:
            stats = loader.get_table_stats('dwh_shopify_orders')
            print(f"ğŸ“Š dwh_shopify_ordersçµ±è¨ˆ: {stats['total_count']}ä»¶")
        except:
            print("ğŸ“Š dwh_shopify_ordersãƒ†ãƒ¼ãƒ–ãƒ«ã¯æœªä½œæˆï¼ˆAlembicãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¾…ã¡ï¼‰")
        
        print("âœ… ãƒ†ã‚¹ãƒˆå®Œäº†")
        
        # æ˜ç¤ºçš„ãªãƒªã‚½ãƒ¼ã‚¹è§£æ”¾
        loader.close_pool()
        
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆå¤±æ•—: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)