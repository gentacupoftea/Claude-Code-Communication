#!/usr/bin/env python3
"""
MultiLLM System Test Script
Phase 1ã®å®Ÿè£…ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ç°¡æ˜“ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import asyncio
import sys
import os
import json
from datetime import datetime

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from orchestrator.orchestrator import MultiLLMOrchestrator, TaskType
from services.memory_sync import MemorySyncService
from workers.base_worker import BaseWorker, WorkerTask
from config.config_validator import ConfigValidator
from services.rate_limiter import MultiProviderRateLimiter


async def test_config_validation():
    """è¨­å®šæ¤œè¨¼ã®ãƒ†ã‚¹ãƒˆ"""
    print("\n=== Testing Config Validation ===")
    try:
        # å¿…è¦ãªç’°å¢ƒå¤‰æ•°ã‚’ä»®è¨­å®šï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
        test_env = {
            'SLACK_BOT_TOKEN': 'xoxb-test-token',
            'SLACK_SIGNING_SECRET': 'test-secret',
            'SLACK_BOT_ID': 'U123456789',
            'OPENAI_API_KEY': 'sk-test-openai-key',
            'ANTHROPIC_API_KEY': 'sk-ant-test-key',
            'GOOGLE_AI_API_KEY': 'test-google-key',
            'OPENMEMORY_URL': 'http://localhost:8765'
        }
        
        for key, value in test_env.items():
            if not os.getenv(key):
                os.environ[key] = value
        
        config = ConfigValidator.create_default_config()
        validated_config = ConfigValidator.validate_config(config)
        print("âœ… Configuration validation passed")
        print(f"   - Workers: {list(validated_config['workers'].keys())}")
        print(f"   - Memory sync interval: {validated_config['memory']['syncInterval']}s")
        
    except Exception as e:
        print(f"âŒ Configuration validation failed: {e}")
        return False
    
    return True


async def test_orchestrator():
    """Orchestratorã®ãƒ†ã‚¹ãƒˆ"""
    print("\n=== Testing Orchestrator ===")
    
    config = {
        "workers": {
            "backend_worker": {"model": "gpt-4-turbo"},
            "frontend_worker": {"model": "claude-3-sonnet"},
            "review_worker": {"model": "gpt-4"}
        },
        "memory": {
            "syncInterval": 300
        }
    }
    
    orchestrator = MultiLLMOrchestrator(config)
    await orchestrator.initialize()
    
    # ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—åˆ¤å®šãƒ†ã‚¹ãƒˆ
    test_requests = [
        ("ãƒã‚°ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„", TaskType.CODE_IMPLEMENTATION),
        ("UIã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’æ”¹å–„ã—ã¦", TaskType.UI_DESIGN),
        ("READMEã‚’æ›´æ–°ã—ã¦", TaskType.DOCUMENTATION),
        ("PRã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦", TaskType.PR_REVIEW),
        ("ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã¦", TaskType.DATA_ANALYSIS),
        ("ç”»åƒã‚’ç”Ÿæˆã—ã¦", TaskType.IMAGE_GENERATION)
    ]
    
    for request, expected_type in test_requests:
        task_type = orchestrator._analyze_task_type(request)
        status = "âœ…" if task_type == expected_type else "âŒ"
        print(f"{status} '{request}' -> {task_type.value}")
    
    # ç°¡å˜ãªãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†
    result = await orchestrator.process_user_request(
        "ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã„ã¦ãã ã•ã„",
        user_id="test_user"
    )
    print(f"âœ… Request processed: {result['result']}")
    
    return True


async def test_memory_sync():
    """Memory Syncã®ãƒ†ã‚¹ãƒˆ"""
    print("\n=== Testing Memory Sync ===")
    
    config = {
        'syncInterval': 300,
        'conflictResolution': 'latest',
        'storage': {
            'type': 'openmemory',
            'connectionString': os.getenv('OPENMEMORY_URL', 'http://localhost:8765')
        }
    }
    
    service = MemorySyncService(config)
    
    # URLæ¤œè¨¼ãƒ†ã‚¹ãƒˆ
    test_urls = [
        ("http://localhost:8765", True),
        ("https://openmemory.internal", True),
        ("ftp://badurl.com", False),
        ("javascript:alert(1)", False),
        ("", False)
    ]
    
    for url, expected in test_urls:
        result = service._validate_url(url)
        status = "âœ…" if result == expected else "âŒ"
        print(f"{status} URL validation: '{url}' -> {result}")
    
    # ãƒ¡ãƒ¢ãƒªè¿½åŠ ãƒ†ã‚¹ãƒˆ
    await service.add_memory(
        worker_name='test_worker',
        content='ãƒ†ã‚¹ãƒˆãƒ¡ãƒ¢ãƒªã‚¨ãƒ³ãƒˆãƒªãƒ¼',
        metadata={'test': True},
        importance=0.8
    )
    print("âœ… Memory entry added")
    
    return True


async def test_rate_limiter():
    """Rate Limiterã®ãƒ†ã‚¹ãƒˆ"""
    print("\n=== Testing Rate Limiter ===")
    
    rate_limiter = MultiProviderRateLimiter()
    
    # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒã‚§ãƒƒã‚¯
    providers = [
        ('openai', 'gpt-4-turbo'),
        ('anthropic', 'claude-3-sonnet'),
        ('google', 'gemini-1.5-flash')
    ]
    
    for provider, model in providers:
        can_proceed, wait_time = await rate_limiter.check_rate_limit(provider, model, 1000)
        status = "âœ…" if can_proceed else "â³"
        print(f"{status} {provider}:{model} - Can proceed: {can_proceed}")
    
    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º
    status = rate_limiter.get_all_status()
    print("\nğŸ“Š Rate Limiter Status:")
    for provider, models in status.items():
        print(f"  {provider}:")
        for model, info in models.items():
            print(f"    {model}: {info['requests_used']}/{info['requests_limit']} requests")
    
    return True


async def test_worker():
    """Workerã®ãƒ†ã‚¹ãƒˆ"""
    print("\n=== Testing Worker ===")
    
    config = {
        'model': 'gpt-4',
        'maxConcurrentTasks': 3,
        'maxQueueSize': 10,
        'maxMemoryEntries': 100
    }
    
    worker = BaseWorker("test_worker", config)
    await worker.initialize()
    
    # ã‚¿ã‚¹ã‚¯é€ä¿¡ãƒ†ã‚¹ãƒˆ
    task = WorkerTask(
        id="test-001",
        type="test",
        description="ãƒ†ã‚¹ãƒˆã‚¿ã‚¹ã‚¯",
        context={"test": True}
    )
    
    task_id = await worker.submit_task(task)
    print(f"âœ… Task submitted: {task_id}")
    
    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª
    status = worker.get_status()
    print(f"ğŸ“Š Worker Status:")
    print(f"   - Active tasks: {status['active_tasks']}")
    print(f"   - Queued tasks: {status['queued_tasks']}")
    print(f"   - Success rate: {status['metrics']['successful_tasks']}/{status['metrics']['total_tasks']}")
    
    # ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³
    await worker.shutdown()
    print("âœ… Worker shutdown complete")
    
    return True


async def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("ğŸš€ MultiLLM System Phase 1 Test")
    print("=" * 40)
    
    tests = [
        ("Config Validation", test_config_validation),
        ("Orchestrator", test_orchestrator),
        ("Memory Sync", test_memory_sync),
        ("Rate Limiter", test_rate_limiter),
        ("Worker", test_worker)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            success = await test_func()
            results.append((test_name, success))
        except Exception as e:
            print(f"\nâŒ {test_name} failed with error: {e}")
            results.append((test_name, False))
    
    # çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 40)
    print("ğŸ“Š Test Results Summary:")
    print("=" * 40)
    
    passed = sum(1 for _, success in results if success)
    total = len(results)
    
    for test_name, success in results:
        status = "âœ… PASSED" if success else "âŒ FAILED"
        print(f"{test_name:.<30} {status}")
    
    print(f"\nTotal: {passed}/{total} tests passed")
    
    if passed == total:
        print("\nğŸ‰ All tests passed! Phase 1 implementation is working correctly.")
    else:
        print("\nâš ï¸  Some tests failed. Please check the implementation.")


if __name__ == "__main__":
    asyncio.run(main())