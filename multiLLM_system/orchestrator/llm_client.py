"""
LLM Client - OpenAI GPT-4 Integration
Orchestratorã§GPT-4ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
"""

import asyncio
import logging
import json
from typing import Dict, List, Any, Optional, AsyncGenerator
from dataclasses import dataclass
import aiohttp
import os
from datetime import datetime

logger = logging.getLogger(__name__)


@dataclass
class LLMMessage:
    """LLMãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"""
    role: str  # "user", "assistant", "system"
    content: str
    timestamp: datetime = None


@dataclass
class TaskAnalysis:
    """ã‚¿ã‚¹ã‚¯åˆ†æçµæœ"""
    task_type: str
    priority: str
    complexity: str  # "simple", "complex"
    subtasks: List[str]
    assigned_workers: List[str]
    reasoning: str


class ClaudeClient:
    """OpenAI GPT-4 ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆClaudeäº’æ›ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼‰"""
    
    def __init__(self, api_key: str = None):
        # OpenAI APIã‚­ãƒ¼ã‚’å„ªå…ˆã€ãªã‘ã‚Œã°ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰
        self.api_key = api_key or os.getenv('OPENAI_API_KEY') or os.getenv('ANTHROPIC_API_KEY')
        self.base_url = "https://api.openai.com/v1/chat/completions"
        self.model = "gpt-4-turbo-preview"  # GPT-4 Turbo
        self.session = None
        self.demo_mode = False
        
        # ãƒ‡ãƒãƒƒã‚°ç”¨: APIã‚­ãƒ¼ã®å­˜åœ¨ç¢ºèª
        if self.api_key:
            if 'sk-' in self.api_key and len(self.api_key) > 20:
                logger.info(f"ğŸ”‘ OpenAI API Key found: {self.api_key[:7]}...{self.api_key[-4:]}")
            else:
                logger.warning("âš ï¸ Invalid API key format. Using enhanced demo mode.")
                self.demo_mode = True
        else:
            logger.warning("âš ï¸ No API key found. Using enhanced demo mode.")
            self.demo_mode = True
    
    async def initialize(self):
        """ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–"""
        if self.api_key and not self.demo_mode:
            self.session = aiohttp.ClientSession()
            logger.info("âœ… LLM API client initialized")
            
            # APIæ¥ç¶šãƒ†ã‚¹ãƒˆ
            try:
                test_response = await self._test_api_connection()
                if test_response:
                    logger.info("ğŸŸ¢ API connection test successful")
                else:
                    logger.error("ğŸ”´ API connection test failed")
                    self.demo_mode = True
            except Exception as e:
                logger.error(f"ğŸ”´ API test error: {e}")
                self.demo_mode = True
        else:
            logger.info("ğŸ”„ LLM client in enhanced demo mode")
            self.session = aiohttp.ClientSession()  # ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã§ã‚‚ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ
    
    async def _test_api_connection(self) -> bool:
        """APIæ¥ç¶šãƒ†ã‚¹ãƒˆ"""
        if not self.session:
            return False
            
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": "gpt-3.5-turbo",  # ãƒ†ã‚¹ãƒˆç”¨ã«è»½é‡ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨
            "messages": [{"role": "user", "content": "Hi"}],
            "max_tokens": 5
        }
        
        try:
            async with self.session.post(self.base_url, headers=headers, json=payload) as response:
                if response.status == 200:
                    return True
                else:
                    error_text = await response.text()
                    logger.error(f"API test failed: {response.status} - {error_text}")
                    return False
        except Exception as e:
            logger.error(f"API test exception: {e}")
            return False
    
    async def shutdown(self):
        """ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆçµ‚äº†"""
        if self.session:
            await self.session.close()
    
    async def analyze_task(self, user_request: str, context: Dict = None) -> TaskAnalysis:
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’åˆ†æã—ã¦ã‚¿ã‚¹ã‚¯è¨ˆç”»ã‚’ç«‹ã¦ã‚‹
        """
        system_prompt = """ã‚ãªãŸã¯é«˜åº¦ãªAIã‚¿ã‚¹ã‚¯ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’åˆ†æã—ã€ä»¥ä¸‹ã®è¦³ç‚¹ã§åˆ†é¡ãƒ»è¨ˆç”»ã—ã¦ãã ã•ã„ï¼š

1. **ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—åˆ†é¡**:
   - MEMORY_OPERATION: ãƒ¡ãƒ¢ãƒªæ¤œç´¢ãƒ»ä¿å­˜ãƒ»å‰Šé™¤æ“ä½œ
   - CODE_IMPLEMENTATION: ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ãƒ»å®Ÿè£…ã‚¿ã‚¹ã‚¯
   - UI_DESIGN: UI/UXãƒ‡ã‚¶ã‚¤ãƒ³é–¢é€£
   - DATA_ANALYSIS: ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ»çµ±è¨ˆå‡¦ç†
   - DOCUMENTATION: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆãƒ»èª¬æ˜
   - PROJECT_MANAGEMENT: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†ãƒ»é€²æ—ç¢ºèª
   - GENERAL: ä¸€èˆ¬çš„ãªè³ªå•ãƒ»å¯¾è©±

2. **å„ªå…ˆåº¦**: CRITICAL, HIGH, MEDIUM, LOW

3. **è¤‡é›‘åº¦**: 
   - simple: å˜ä¸€ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã§å‡¦ç†å¯èƒ½
   - complex: è¤‡æ•°ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚„ã‚¹ãƒ†ãƒƒãƒ—ãŒå¿…è¦

4. **ã‚µãƒ–ã‚¿ã‚¹ã‚¯åˆ†è§£**: è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã®å ´åˆ

5. **ãƒ¯ãƒ¼ã‚«ãƒ¼å‰²ã‚Šå½“ã¦**: æœ€é©ãªãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’é¸æŠ
   - mcp_worker: OpenMemoryæ“ä½œ
   - backend_worker: ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰å®Ÿè£…
   - frontend_worker: UI/ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰
   - analytics_worker: ãƒ‡ãƒ¼ã‚¿åˆ†æ
   - documentation_worker: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
   - project_manager: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†

JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"""
        
        user_message = f"""
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {user_request}

ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {json.dumps(context or {}, ensure_ascii=False)}

ã“ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’åˆ†æã—ã¦ã‚¿ã‚¹ã‚¯è¨ˆç”»ã‚’ç«‹ã¦ã¦ãã ã•ã„ã€‚
"""
        
        if self.api_key and self.session:
            # å®Ÿéš›ã®Claude APIå‘¼ã³å‡ºã—
            response = await self._call_claude_api(system_prompt, user_message)
            try:
                result = json.loads(response)
                return TaskAnalysis(
                    task_type=result.get('task_type', 'GENERAL'),
                    priority=result.get('priority', 'MEDIUM'),
                    complexity=result.get('complexity', 'simple'),
                    subtasks=result.get('subtasks', []),
                    assigned_workers=result.get('assigned_workers', ['backend_worker']),
                    reasoning=result.get('reasoning', 'è‡ªå‹•åˆ†æã«ã‚ˆã‚‹åˆ†é¡')
                )
            except json.JSONDecodeError:
                logger.error("Failed to parse Claude API response as JSON")
                return self._fallback_analysis(user_request)
        else:
            # ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ï¼ˆClaude APIã‚­ãƒ¼ãªã—ï¼‰
            return self._demo_task_analysis(user_request)
    
    async def _call_claude_api(self, system_prompt: str, user_message: str) -> str:
        """OpenAI APIå‘¼ã³å‡ºã—ï¼ˆClaudeäº’æ›ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼‰"""
        if self.demo_mode:
            return await self._enhanced_demo_response(user_message, system_prompt)
            
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_message}
        ]
        
        payload = {
            "model": self.model,
            "messages": messages,
            "max_tokens": 2000,
            "temperature": 0.7
        }
        
        try:
            async with self.session.post(self.base_url, headers=headers, json=payload) as response:
                if response.status == 200:
                    data = await response.json()
                    return data['choices'][0]['message']['content']
                else:
                    error_text = await response.text()
                    logger.error(f"API error {response.status}: {error_text}")
                    return await self._enhanced_demo_response(user_message, system_prompt)
        except Exception as e:
            logger.error(f"API call failed: {e}")
            return await self._enhanced_demo_response(user_message, system_prompt)
    
    def _demo_task_analysis(self, user_request: str) -> TaskAnalysis:
        """ãƒ‡ãƒ¢ç”¨ã®ã‚¿ã‚¹ã‚¯åˆ†æï¼ˆClaude APIã‚­ãƒ¼ãªã—ã®å ´åˆï¼‰"""
        request_lower = user_request.lower()
        
        # ç°¡å˜ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹åˆ†æï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰
        if any(kw in request_lower for kw in ['æ€ã„å‡ºã—ã¦', 'è¨˜æ†¶ã—ã¦', 'ä¿å­˜ã—ã¦', 'ãƒ¡ãƒ¢ãƒª']):
            return TaskAnalysis(
                task_type='MEMORY_OPERATION',
                priority='MEDIUM',
                complexity='simple',
                subtasks=[user_request],
                assigned_workers=['mcp_worker'],
                reasoning='ãƒ¡ãƒ¢ãƒªæ“ä½œã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œå‡º'
            )
        
        elif any(kw in request_lower for kw in ['ã‚³ãƒ¼ãƒ‰', 'ãƒ—ãƒ­ã‚°ãƒ©ãƒ ', 'api', 'ãƒã‚°']):
            return TaskAnalysis(
                task_type='CODE_IMPLEMENTATION',
                priority='MEDIUM',
                complexity='simple',
                subtasks=[user_request],
                assigned_workers=['backend_worker'],
                reasoning='ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œå‡º'
            )
        
        elif any(kw in request_lower for kw in ['ui', 'ãƒ‡ã‚¶ã‚¤ãƒ³', 'react', 'ãƒ•ãƒ­ãƒ³ãƒˆ']):
            return TaskAnalysis(
                task_type='UI_DESIGN',
                priority='MEDIUM',
                complexity='simple',
                subtasks=[user_request],
                assigned_workers=['frontend_worker'],
                reasoning='UI/ãƒ‡ã‚¶ã‚¤ãƒ³é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œå‡º'
            )
        
        elif any(kw in request_lower for kw in ['ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ', 'é€²æ—', 'ã‚¬ãƒ³ãƒˆ', 'ã‚¿ã‚¹ã‚¯ç®¡ç†']):
            return TaskAnalysis(
                task_type='PROJECT_MANAGEMENT',
                priority='HIGH',
                complexity='complex',
                subtasks=[
                    'ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã®åé›†',
                    'ã‚¿ã‚¹ã‚¯çŠ¶æ³ã®åˆ†æ',
                    'ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ'
                ],
                assigned_workers=['analytics_worker', 'documentation_worker'],
                reasoning='ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†é–¢é€£ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œå‡º'
            )
        
        else:
            return TaskAnalysis(
                task_type='GENERAL',
                priority='MEDIUM',
                complexity='simple',
                subtasks=[user_request],
                assigned_workers=['backend_worker'],
                reasoning='ä¸€èˆ¬çš„ãªè³ªå•ã¨ã—ã¦åˆ†é¡'
            )
    
    def _fallback_analysis(self, user_request: str) -> TaskAnalysis:
        """APIå‘¼ã³å‡ºã—å¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        return self._demo_task_analysis(user_request)
    
    def _fallback_response(self, user_message: str) -> str:
        """APIå‘¼ã³å‡ºã—å¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”"""
        # ã‚¿ã‚¹ã‚¯åˆ†æç”¨ã®JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹
        return json.dumps({
            "task_type": "GENERAL",
            "priority": "MEDIUM",
            "complexity": "simple",
            "subtasks": [user_message],
            "assigned_workers": ["backend_worker"],
            "reasoning": "APIå‘¼ã³å‡ºã—å¤±æ•—ã«ã‚ˆã‚‹ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ†æ"
        }, ensure_ascii=False)
    
    async def generate_response(self, messages: List[LLMMessage], context: Dict = None, stream_callback=None) -> str:
        """
        ä¸€èˆ¬çš„ãªä¼šè©±å¿œç­”ã‚’ç”Ÿæˆ
        """
        user_message = messages[-1].content if messages else ""
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        system_prompt = """ã‚ãªãŸã¯è¦ªåˆ‡ã§çŸ¥è­˜è±Šå¯ŒãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«é©åˆ‡ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚"""
        
        if self.demo_mode:
            # å¼·åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰
            response = await self._enhanced_demo_response(user_message, system_prompt)
            if stream_callback:
                # ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã§ã‚‚ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
                for i in range(0, len(response), 20):
                    chunk = response[i:i+20]
                    await stream_callback(chunk)
                    await asyncio.sleep(0.05)  # è‡ªç„¶ãªã‚¿ã‚¤ãƒ”ãƒ³ã‚°é€Ÿåº¦
            return response
        
        try:
            if stream_callback:
                # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œã®APIå‘¼ã³å‡ºã—
                return await self._call_claude_api_stream(system_prompt, user_message, stream_callback)
            else:
                response = await self._call_claude_api(system_prompt, user_message)
                return response
        except Exception as e:
            # APIå¤±æ•—æ™‚ã¯å¼·åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã®å¿œç­”ã‚’ä½¿ç”¨
            logger.error(f"API failed, using enhanced demo response: {e}")
            return await self._enhanced_demo_response(user_message, system_prompt)
    
    async def _call_claude_api_stream(self, system_prompt: str, user_message: str, stream_callback) -> str:
        """OpenAI APIã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‘¼ã³å‡ºã—ï¼ˆClaudeäº’æ›ï¼‰"""
        if self.demo_mode:
            # ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã§ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
            response = await self._enhanced_demo_response(user_message, system_prompt)
            for i in range(0, len(response), 20):
                chunk = response[i:i+20]
                await stream_callback(chunk)
                await asyncio.sleep(0.05)
            return response
            
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_message}
        ]
        
        payload = {
            "model": self.model,
            "messages": messages,
            "max_tokens": 2000,
            "temperature": 0.7,
            "stream": True
        }
        
        full_response = ""
        
        try:
            async with self.session.post(self.base_url, headers=headers, json=payload) as response:
                if response.status == 200:
                    async for line in response.content:
                        if line:
                            line_str = line.decode('utf-8').strip()
                            if line_str.startswith('data: '):
                                data_str = line_str[6:]
                                if data_str == '[DONE]':
                                    break
                                try:
                                    data = json.loads(data_str)
                                    if 'choices' in data and len(data['choices']) > 0:
                                        delta = data['choices'][0].get('delta', {})
                                        if 'content' in delta:
                                            chunk = delta['content']
                                            full_response += chunk
                                            await stream_callback(chunk)
                                except json.JSONDecodeError:
                                    continue
                    return full_response
                else:
                    error_text = await response.text()
                    logger.error(f"API stream error {response.status}: {error_text}")
                    return await self._enhanced_demo_response(user_message, system_prompt)
        except Exception as e:
            logger.error(f"API stream call failed: {e}")
            return await self._enhanced_demo_response(user_message, system_prompt)
    
    def _demo_response(self, user_message: str) -> str:
        """ãƒ‡ãƒ¢ç”¨ã®å¿œç­”ç”Ÿæˆï¼ˆã‚ˆã‚ŠçŸ¥çš„ãªå¿œç­”ï¼‰"""
        message_lower = user_message.lower()
        
        if "ã“ã‚“ã«ã¡ã¯" in user_message or "hello" in message_lower:
            return """ã“ã‚“ã«ã¡ã¯ï¼MultiLLM Orchestratorã‚·ã‚¹ãƒ†ãƒ ã¸ã‚ˆã†ã“ãã€‚

ç§ã¯Claude-4ãƒ™ãƒ¼ã‚¹ã®AIã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚ä»¥ä¸‹ã®ã‚ˆã†ãªæ©Ÿèƒ½ã‚’æä¾›ã—ã¦ã„ã¾ã™ï¼š

ğŸ§  **çŸ¥çš„ã‚¿ã‚¹ã‚¯åˆ†æ**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ç†è§£ã—ã€æœ€é©ãªãƒ¯ãƒ¼ã‚«ãƒ¼ã«æŒ¯ã‚Šåˆ†ã‘
ğŸ”§ **å°‚é–€Workeré€£æº**: å„åˆ†é‡ã®å°‚é–€AIãƒ¯ãƒ¼ã‚«ãƒ¼ã¨é€£æº
ğŸ’¾ **ãƒ¡ãƒ¢ãƒªçµ±åˆ**: OpenMemoryã‚’ä½¿ã£ãŸé•·æœŸè¨˜æ†¶
ğŸ“Š **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†**: ã‚¿ã‚¹ã‚¯ã®é€²æ—ç®¡ç†ã¨åˆ†æ

ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ãŒã‚ã‚Œã°ã€ãŠæ°—è»½ã«ãŠç”³ã—ä»˜ã‘ãã ã•ã„ï¼"""
        
        elif "ã‚ã‚ŠãŒã¨ã†" in user_message or "thank" in message_lower:
            return "ã©ã†ã„ãŸã—ã¾ã—ã¦ï¼ä»–ã«ã‚‚ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ãŒã‚ã‚Œã°ã€ã„ã¤ã§ã‚‚ãŠå£°ã‹ã‘ãã ã•ã„ã€‚MultiLLM Orchestratorã‚·ã‚¹ãƒ†ãƒ ãŒãŠå½¹ã«ç«‹ã¦ã¦å¬‰ã—ã„ã§ã™ã€‚"
        
        elif "ä½•ãŒã§ãã‚‹" in user_message or "æ©Ÿèƒ½" in user_message or "help" in message_lower:
            return """MultiLLM Orchestratorã‚·ã‚¹ãƒ†ãƒ ã§ã¯ä»¥ä¸‹ã®ã“ã¨ãŒã§ãã¾ã™ï¼š

**ğŸ’» é–‹ç™ºæ”¯æ´**:
- ã‚³ãƒ¼ãƒ‰å®Ÿè£…ãƒ»ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ»ãƒ‡ãƒãƒƒã‚°
- UI/UXãƒ‡ã‚¶ã‚¤ãƒ³ã®ææ¡ˆã¨å®Ÿè£…
- APIè¨­è¨ˆã¨ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰é–‹ç™º

**ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ»åˆ†æ**:
- ãƒ‡ãƒ¼ã‚¿åˆ†æã¨å¯è¦–åŒ–
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé€²æ—ã®ç®¡ç†
- ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ

**ğŸ’¾ ãƒ¡ãƒ¢ãƒªæ©Ÿèƒ½**:
- é‡è¦ãªæƒ…å ±ã®è¨˜æ†¶ãƒ»æ¤œç´¢
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã®ç®¡ç†
- éå»ã®ä¼šè©±ã®æŒ¯ã‚Šè¿”ã‚Š

**ğŸ“ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**:
- æŠ€è¡“ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä½œæˆ
- ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ãƒ»ã‚¬ã‚¤ãƒ‰ã®ç”Ÿæˆ
- èª¬æ˜æ–‡ã®ä½œæˆ

å…·ä½“çš„ã«ã‚„ã‚ŠãŸã„ã“ã¨ãŒã‚ã‚Œã°ã€è‡ªç„¶ãªè¨€è‘‰ã§è©±ã—ã‹ã‘ã¦ãã ã•ã„ï¼"""
        
        elif "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ" in user_message:
            return f"ã€Œ{user_message}ã€ã«ã¤ã„ã¦ã§ã™ã­ã€‚ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé–¢é€£ã®ã”è³ªå•ã‚„ã‚¿ã‚¹ã‚¯ã¯ç§ã®å¾—æ„åˆ†é‡ã§ã™ã€‚å…·ä½“çš„ã«ã©ã®ã‚ˆã†ãªã‚µãƒãƒ¼ãƒˆãŒå¿…è¦ã§ã—ã‚‡ã†ã‹ï¼Ÿé€²æ—ç®¡ç†ã€ã‚¿ã‚¹ã‚¯åˆ†æã€ãƒ¡ãƒ³ãƒãƒ¼ç®¡ç†ãªã©ã€æ§˜ã€…ãªè§’åº¦ã‹ã‚‰ãŠæ‰‹ä¼ã„ã§ãã¾ã™ã€‚"
        
        elif "ä½œæˆ" in user_message or "ä½œã£ã¦" in user_message or "å®Ÿè£…" in user_message:
            return f"ã€Œ{user_message}ã€ã®ä½œæˆã«ã¤ã„ã¦ã‚µãƒãƒ¼ãƒˆã„ãŸã—ã¾ã™ã€‚ã©ã®ã‚ˆã†ãªæŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ã‚„è¦ä»¶ã‚’ãŠè€ƒãˆã§ã—ã‚‡ã†ã‹ï¼Ÿè©³ç´°ã‚’ãŠèã‹ã›ã„ãŸã ã‘ã‚Œã°ã€æœ€é©ãªå®Ÿè£…æ–¹é‡ã‚’ææ¡ˆã„ãŸã—ã¾ã™ã€‚"
        
        elif "åˆ†æ" in user_message or "ãƒ‡ãƒ¼ã‚¿" in user_message:
            return f"ã€Œ{user_message}ã€ã«ã¤ã„ã¦ãƒ‡ãƒ¼ã‚¿åˆ†æã®å°‚é–€ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒã‚µãƒãƒ¼ãƒˆã„ãŸã—ã¾ã™ã€‚ã©ã®ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã‚’ãŠæŒã¡ã§ã€ã©ã®ã‚ˆã†ãªåˆ†æã‚’ã”å¸Œæœ›ã§ã—ã‚‡ã†ã‹ï¼Ÿå¯è¦–åŒ–ã‚„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚‚å«ã‚ã¦å¯¾å¿œå¯èƒ½ã§ã™ã€‚"
        
        elif "?" in user_message or "ï¼Ÿ" in user_message:
            return f"ã€Œ{user_message}ã€ã¨ã„ã†ã”è³ªå•ã§ã™ã­ã€‚è©³ã—ãèª¿ã¹ã¦ãŠç­”ãˆã„ãŸã—ã¾ã™ã€‚ã“ã®è³ªå•ã«é–¢é€£ã—ã¦ã€è¿½åŠ ã§çŸ¥ã‚ŠãŸã„ã“ã¨ã‚„ã€ç‰¹å®šã®è¦³ç‚¹ã‹ã‚‰ã®æƒ…å ±ãŒå¿…è¦ã§ã—ãŸã‚‰ãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚"
        
        else:
            return f"ã€Œ{user_message}ã€ã«ã¤ã„ã¦æ‰¿çŸ¥ã„ãŸã—ã¾ã—ãŸã€‚\n\nã“ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’åˆ†æã—ã¦ã€æœ€é©ãªæ–¹æ³•ã§å¯¾å¿œã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚ã‚‚ã—ã‚ˆã‚Šå…·ä½“çš„ãªè¦ä»¶ã‚„èƒŒæ™¯æƒ…å ±ãŒã‚ã‚Œã°ã€ãŠèã‹ã›ãã ã•ã„ã€‚ã‚ˆã‚Šè©³ç´°ã§æœ‰ç”¨ãªå›ç­”ã‚’æä¾›ã§ãã¾ã™ã€‚"
    
    async def _enhanced_demo_response(self, user_message: str, system_prompt: str = "") -> str:
        """å¼·åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¢å¿œç­”ï¼ˆAIã£ã½ã„å‹•çš„ãªå¿œç­”ï¼‰"""
        import random
        import re
        
        message_lower = user_message.lower()
        
        # æ™‚åˆ»ãƒ™ãƒ¼ã‚¹ã®æŒ¨æ‹¶
        from datetime import datetime
        current_hour = datetime.now().hour
        
        if "ã“ã‚“ã«ã¡ã¯" in user_message or "hello" in message_lower:
            if current_hour < 12:
                greeting = "ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™"
            elif current_hour < 18:
                greeting = "ã“ã‚“ã«ã¡ã¯"
            else:
                greeting = "ã“ã‚“ã°ã‚“ã¯"
            
            responses = [
                f"{greeting}ï¼æœ¬æ—¥ã¯ã©ã®ã‚ˆã†ãªã“ã¨ã§ãŠæ‰‹ä¼ã„ã§ãã¾ã™ã‹ï¼Ÿ",
                f"{greeting}ï¼MultiLLM Orchestratorã‚·ã‚¹ãƒ†ãƒ ã¸ã‚ˆã†ã“ãã€‚ä½•ã‹ãŠå›°ã‚Šã®ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
                f"{greeting}ï¼ãŠä¼šã„ã§ãã¦å¬‰ã—ã„ã§ã™ã€‚ä»Šæ—¥ã¯ã©ã‚“ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«å–ã‚Šçµ„ã¾ã‚Œã¦ã„ã¾ã™ã‹ï¼Ÿ"
            ]
            return random.choice(responses)
        
        # è³ªå•ã¸ã®å¿œç­”
        elif "?" in user_message or "ï¼Ÿ" in user_message:
            # æŠ€è¡“çš„ãªè³ªå•
            if any(word in message_lower for word in ['python', 'javascript', 'react', 'api', 'ãƒ—ãƒ­ã‚°ãƒ©ãƒ ', 'ã‚³ãƒ¼ãƒ‰']):
                return f"""ã”è³ªå•ã®ã€Œ{user_message}ã€ã«ã¤ã„ã¦å›ç­”ã„ãŸã—ã¾ã™ã€‚

æŠ€è¡“çš„ãªè¦³ç‚¹ã‹ã‚‰è¦‹ã‚‹ã¨ã€ã„ãã¤ã‹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒè€ƒãˆã‚‰ã‚Œã¾ã™ï¼š

1. **åŸºæœ¬çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**: æ¨™æº–çš„ãªå®Ÿè£…æ–¹æ³•ã‚’æ¡ç”¨ã—ã€ç¢ºå®Ÿæ€§ã‚’é‡è¦–ã™ã‚‹
2. **ãƒ¢ãƒ€ãƒ³ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**: æœ€æ–°ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚„ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’æ´»ç”¨ã™ã‚‹
3. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é‡è¦–**: å‡¦ç†é€Ÿåº¦ã‚„åŠ¹ç‡æ€§ã‚’æœ€å„ªå…ˆã«è€ƒãˆã‚‹

å…·ä½“çš„ãªçŠ¶æ³ã‚„è¦ä»¶ã«å¿œã˜ã¦ã€æœ€é©ãªæ–¹æ³•ã‚’ã”ææ¡ˆã§ãã¾ã™ã€‚è©³ç´°ãªæƒ…å ±ã‚’ãŠèã‹ã›ã„ãŸã ã‘ã‚Œã°ã€ã‚ˆã‚Šå…·ä½“çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ãŒå¯èƒ½ã§ã™ã€‚"""
            
            # ä¸€èˆ¬çš„ãªè³ªå•
            else:
                keywords = re.findall(r'[ä¸€-é¾¥ã-ã‚“ã‚¡-ãƒ¶ãƒ¼]+|[a-zA-Z]+', user_message)
                main_topic = max(keywords, key=len) if keywords else "ãã‚Œ"
                
                return f"""ã€Œ{main_topic}ã€ã«ã¤ã„ã¦ã®ã”è³ªå•ã§ã™ã­ã€‚

ã“ã®ä»¶ã«ã¤ã„ã¦ã€ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰è€ƒãˆã¦ã¿ã¾ã—ã‚‡ã†ï¼š

â€¢ **ç¾çŠ¶åˆ†æ**: ã¾ãšç¾åœ¨ã®çŠ¶æ³ã‚’æ­£ç¢ºã«æŠŠæ¡ã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã™
â€¢ **èª²é¡Œã®ç‰¹å®š**: è§£æ±ºã™ã¹ãå…·ä½“çš„ãªå•é¡Œç‚¹ã‚’æ˜ç¢ºã«ã—ã¾ã™
â€¢ **è§£æ±ºç­–ã®æ¤œè¨**: è¤‡æ•°ã®é¸æŠè‚¢ã‚’æ¯”è¼ƒæ¤œè¨ã—ã¾ã™
â€¢ **å®Ÿè¡Œè¨ˆç”»**: æ®µéšçš„ãªå®Ÿæ–½è¨ˆç”»ã‚’ç«‹ã¦ã¾ã™

ã‚ˆã‚Šè©³ã—ã„æƒ…å ±ãŒã‚ã‚Œã°ã€ã•ã‚‰ã«å…·ä½“çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ã”æä¾›ã§ãã¾ã™ã€‚"""
        
        # ä½œæˆãƒ»å®Ÿè£…ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        elif any(word in message_lower for word in ['ä½œæˆ', 'ä½œã£ã¦', 'å®Ÿè£…', 'create', 'implement']):
            return f"""ã€Œ{user_message}ã€ã®å®Ÿè£…ã«ã¤ã„ã¦æ‰¿ã‚Šã¾ã—ãŸã€‚

ä»¥ä¸‹ã®ã‚¹ãƒ†ãƒƒãƒ—ã§é€²ã‚ã‚‹ã“ã¨ã‚’ã”ææ¡ˆã—ã¾ã™ï¼š

**ãƒ•ã‚§ãƒ¼ã‚º1: è¦ä»¶å®šç¾©**
- æ©Ÿèƒ½è¦ä»¶ã®æ˜ç¢ºåŒ–
- éæ©Ÿèƒ½è¦ä»¶ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç­‰ï¼‰ã®ç¢ºèª
- åˆ¶ç´„æ¡ä»¶ã®æ´—ã„å‡ºã—

**ãƒ•ã‚§ãƒ¼ã‚º2: è¨­è¨ˆ**
- ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ
- ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆ
- ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹è¨­è¨ˆ

**ãƒ•ã‚§ãƒ¼ã‚º3: å®Ÿè£…**
- ã‚³ã‚¢æ©Ÿèƒ½ã®å®Ÿè£…
- ãƒ†ã‚¹ãƒˆã®ä½œæˆ
- ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æ•´å‚™

ã¾ãšã¯ã©ã®éƒ¨åˆ†ã‹ã‚‰ç€æ‰‹ã—ã¾ã—ã‚‡ã†ã‹ï¼Ÿ"""
        
        # ãƒ¡ãƒ¢ãƒªæ“ä½œ
        elif any(word in message_lower for word in ['è¨˜æ†¶', 'ãƒ¡ãƒ¢ãƒª', 'æ€ã„å‡º', 'ä¿å­˜']):
            if 'æ€ã„å‡º' in user_message or 'æ¤œç´¢' in user_message:
                return "ãƒ¡ãƒ¢ãƒªã‚’æ¤œç´¢ã—ã¦ã„ã¾ã™... è©²å½“ã™ã‚‹æƒ…å ±ã‚’æ¢ã—ã¦ã„ã¾ã™ãŒã€ç¾åœ¨ã¯ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã®ãŸã‚å®Ÿéš›ã®ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹ã¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨ãªã‚Šã¾ã™ã€‚"
            else:
                return "æƒ…å ±ã‚’ãƒ¡ãƒ¢ãƒªã«ä¿å­˜ã™ã‚‹æº–å‚™ãŒã§ãã¾ã—ãŸã€‚ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã®ãŸã‚ã€å®Ÿéš›ã®ä¿å­˜ã¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨ãªã‚Šã¾ã™ãŒã€ã©ã®ã‚ˆã†ãªæƒ…å ±ã‚’è¨˜éŒ²ã—ãŸã„ã§ã™ã‹ï¼Ÿ"
        
        # ãã®ä»–ã®ä¸€èˆ¬çš„ãªå¿œç­”
        else:
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®é•·ã•ã«å¿œã˜ãŸå¿œç­”
            if len(user_message) < 10:
                return "ã‚‚ã†å°‘ã—è©³ã—ãæ•™ãˆã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿã‚ˆã‚Šå…·ä½“çš„ãªæƒ…å ±ãŒã‚ã‚Œã°ã€çš„ç¢ºãªã‚µãƒãƒ¼ãƒˆãŒå¯èƒ½ã§ã™ã€‚"
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºã—ã¦å¿œç­”
            keywords = re.findall(r'[ä¸€-é¾¥ã-ã‚“ã‚¡-ãƒ¶ãƒ¼]+|[a-zA-Z]+', user_message)
            if keywords:
                main_topic = max(keywords, key=len)
                return f"""ã€Œ{main_topic}ã€ã«é–¢ã™ã‚‹ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æ‰¿ã‚Šã¾ã—ãŸã€‚

ç¾åœ¨ã€ä»¥ä¸‹ã®ã‚ˆã†ãªå¯¾å¿œãŒå¯èƒ½ã§ã™ï¼š

1. **æƒ…å ±åé›†ã¨åˆ†æ**: é–¢é€£æƒ…å ±ã‚’æ•´ç†ã—ã€ç¾çŠ¶ã‚’æŠŠæ¡ã—ã¾ã™
2. **è¨ˆç”»ç«‹æ¡ˆ**: ç›®æ¨™é”æˆã®ãŸã‚ã®å…·ä½“çš„ãªè¨ˆç”»ã‚’ä½œæˆã—ã¾ã™
3. **å®Ÿè¡Œæ”¯æ´**: å®Ÿéš›ã®ä½œæ¥­ã‚’ã‚µãƒãƒ¼ãƒˆã—ã€é€²æ—ã‚’ç®¡ç†ã—ã¾ã™
4. **è©•ä¾¡ã¨æ”¹å–„**: çµæœã‚’è©•ä¾¡ã—ã€æ”¹å–„ç‚¹ã‚’ææ¡ˆã—ã¾ã™

ã©ã®æ®µéšã‹ã‚‰ã‚µãƒãƒ¼ãƒˆãŒå¿…è¦ã§ã—ã‚‡ã†ã‹ï¼ŸãŠæ°—è»½ã«ãŠç”³ã—ä»˜ã‘ãã ã•ã„ã€‚"""
            
            return self._demo_response(user_message)


# ãƒ†ã‚¹ãƒˆç”¨
async def test_claude_client():
    """Claude Client ã®ãƒ†ã‚¹ãƒˆ"""
    client = ClaudeClient()
    await client.initialize()
    
    # ã‚¿ã‚¹ã‚¯åˆ†æãƒ†ã‚¹ãƒˆ
    analysis = await client.analyze_task("Coneaãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ã¤ã„ã¦æ€ã„å‡ºã—ã¦")
    print("Task Analysis:", analysis)
    
    # å¿œç­”ç”Ÿæˆãƒ†ã‚¹ãƒˆ
    messages = [LLMMessage(role="user", content="ã“ã‚“ã«ã¡ã¯")]
    response = await client.generate_response(messages)
    print("Response:", response)
    
    await client.shutdown()


if __name__ == "__main__":
    asyncio.run(test_claude_client())