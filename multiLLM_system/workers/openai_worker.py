"""
OpenAI GPT Worker
Handles general AI tasks using OpenAI's GPT models
"""

import os
import json
import logging
import asyncio
from typing import Dict, Any, Optional
from base_worker import BaseWorker, WorkerCapability
import openai
from openai import AsyncOpenAI

logger = logging.getLogger(__name__)

class OpenAIWorker(BaseWorker):
    """Worker that uses OpenAI's GPT models for various tasks"""
    
    def __init__(self, worker_id: str = "openai-worker-001"):
        super().__init__(
            worker_id=worker_id,
            worker_type="openai",
            capabilities=[
                WorkerCapability.CODE_GENERATION,
                WorkerCapability.TEXT_GENERATION,
                WorkerCapability.DOCUMENTATION,
                WorkerCapability.ANALYSIS,
                WorkerCapability.GENERAL,
            ]
        )
        
        # Initialize OpenAI client
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY environment variable is required")
        
        self.client = AsyncOpenAI(api_key=api_key)
        self.model = os.getenv("OPENAI_MODEL", "gpt-4-turbo-preview")
        
    async def _process_task_internal(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """Process task using OpenAI API"""
        try:
            content = task.get("content", "")
            context = task.get("context", {})
            task_type = task.get("task_type", "GENERAL")
            
            # Update thinking process
            await self.update_thinking(task["id"], {
                "type": {"icon": "ğŸ¤–", "label": "OpenAI GPT"},
                "stage": "ã‚¿ã‚¹ã‚¯ã‚’åˆ†æä¸­",
                "steps": [{
                    "description": f"ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—: {task_type}",
                    "detail": f"ãƒ¢ãƒ‡ãƒ«: {self.model}",
                }]
            })
            
            # Build system prompt based on task type
            system_prompt = self._build_system_prompt(task_type, context)
            
            # Create messages
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": content}
            ]
            
            # Add context if available
            if context.get("previous_messages"):
                for msg in context["previous_messages"][-5:]:  # Last 5 messages
                    messages.append({
                        "role": msg.get("role", "user"),
                        "content": msg.get("content", "")
                    })
            
            # Update thinking
            await self.update_thinking(task["id"], {
                "type": {"icon": "ğŸ’­", "label": "ç”Ÿæˆä¸­"},
                "stage": "OpenAI APIã‚’å‘¼ã³å‡ºã—ä¸­",
                "steps": [{
                    "description": "å¿œç­”ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...",
                    "detail": f"ãƒˆãƒ¼ã‚¯ãƒ³æ•°: ~{len(content.split()) * 1.3:.0f}",
                }]
            })
            
            # Call OpenAI API with streaming
            response_content = ""
            chunk_count = 0
            
            stream = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.7,
                max_tokens=2000,
                stream=True
            )
            
            async for chunk in stream:
                if chunk.choices[0].delta.content:
                    chunk_content = chunk.choices[0].delta.content
                    response_content += chunk_content
                    chunk_count += 1
                    
                    # Send streaming update every 10 chunks
                    if chunk_count % 10 == 0:
                        await self.send_streaming_update(task["id"], response_content)
            
            # Final update
            await self.send_streaming_update(task["id"], response_content, is_complete=True)
            
            # Update thinking
            await self.update_thinking(task["id"], {
                "type": {"icon": "âœ…", "label": "å®Œäº†"},
                "stage": "å¿œç­”ç”Ÿæˆå®Œäº†",
                "steps": [{
                    "description": "å¿œç­”ã®ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸ",
                    "detail": f"æ–‡å­—æ•°: {len(response_content)}",
                }]
            })
            
            return {
                "content": response_content,
                "model": self.model,
                "usage": {
                    "prompt_tokens": len(str(messages)) // 4,  # Rough estimate
                    "completion_tokens": len(response_content) // 4,
                },
                "metadata": {
                    "worker_id": self.worker_id,
                    "task_type": task_type,
                }
            }
            
        except Exception as e:
            logger.error(f"Error processing task: {str(e)}")
            await self.update_thinking(task["id"], {
                "type": {"icon": "âŒ", "label": "ã‚¨ãƒ©ãƒ¼"},
                "stage": "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
                "steps": [{
                    "description": f"ã‚¨ãƒ©ãƒ¼: {str(e)}",
                    "detail": "ã‚¿ã‚¹ã‚¯ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
                }]
            })
            raise
    
    def _build_system_prompt(self, task_type: str, context: Dict[str, Any]) -> str:
        """Build system prompt based on task type"""
        base_prompt = "ã‚ãªãŸã¯é«˜åº¦ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
        
        type_prompts = {
            "CODE_GENERATION": "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã¨ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã«ç‰¹åŒ–ã—ã¦ã„ã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰ã¯æ˜ç¢ºã§ã€åŠ¹ç‡çš„ã§ã€ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã«å¾“ã†ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚",
            "TEXT_GENERATION": "ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ã§æœ‰ç›Šãªãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ç”Ÿæˆã«ç‰¹åŒ–ã—ã¦ã„ã¾ã™ã€‚",
            "DOCUMENTATION": "æŠ€è¡“æ–‡æ›¸ã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä½œæˆã«ç‰¹åŒ–ã—ã¦ã„ã¾ã™ã€‚æ˜ç¢ºã§æ§‹é€ åŒ–ã•ã‚ŒãŸæ–‡æ›¸ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚",
            "ANALYSIS": "ãƒ‡ãƒ¼ã‚¿åˆ†æã¨æ´å¯Ÿã®æä¾›ã«ç‰¹åŒ–ã—ã¦ã„ã¾ã™ã€‚è«–ç†çš„ã§æ ¹æ‹ ã®ã‚ã‚‹åˆ†æã‚’è¡Œã£ã¦ãã ã•ã„ã€‚",
            "UI_DESIGN": "UIãƒ‡ã‚¶ã‚¤ãƒ³ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ã‚¯ã‚¹ãƒšãƒªã‚¨ãƒ³ã‚¹ã«ç‰¹åŒ–ã—ã¦ã„ã¾ã™ã€‚",
            "GENERAL": "å¹…åºƒã„çŸ¥è­˜ã‚’æ´»ç”¨ã—ã¦ã€æ§˜ã€…ãªè³ªå•ã«ç­”ãˆã¾ã™ã€‚"
        }
        
        prompt = base_prompt + " " + type_prompts.get(task_type, type_prompts["GENERAL"])
        
        # Add project context if available
        if context.get("project_name"):
            prompt += f"\n\nç¾åœ¨ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {context['project_name']}"
        if context.get("task_name"):
            prompt += f"\nç¾åœ¨ã®ã‚¿ã‚¹ã‚¯: {context['task_name']}"
        
        return prompt

async def main():
    """Main function to run the worker"""
    try:
        worker = OpenAIWorker()
        logger.info(f"Starting OpenAI Worker: {worker.worker_id}")
        await worker.start()
    except KeyboardInterrupt:
        logger.info("Shutting down worker...")
    except Exception as e:
        logger.error(f"Worker error: {str(e)}")

if __name__ == "__main__":
    asyncio.run(main())