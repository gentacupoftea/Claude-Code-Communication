"""
Claude Worker
Handles AI tasks using Anthropic's Claude models
"""

import os
import json
import logging
import asyncio
from typing import Dict, Any, Optional, List
from base_worker import BaseWorker, WorkerCapability
import anthropic
from anthropic import AsyncAnthropic

logger = logging.getLogger(__name__)

class ClaudeWorker(BaseWorker):
    """Worker that uses Anthropic's Claude models for various tasks"""
    
    def __init__(self, worker_id: str = "claude-worker-001"):
        super().__init__(
            worker_id=worker_id,
            worker_type="claude",
            capabilities=[
                WorkerCapability.CODE_GENERATION,
                WorkerCapability.TEXT_GENERATION,
                WorkerCapability.DOCUMENTATION,
                WorkerCapability.ANALYSIS,
                WorkerCapability.GENERAL,
                WorkerCapability.PR_REVIEW,
            ]
        )
        
        # Initialize Anthropic client
        api_key = os.getenv("ANTHROPIC_API_KEY")
        if not api_key:
            raise ValueError("ANTHROPIC_API_KEY environment variable is required")
        
        self.client = AsyncAnthropic(api_key=api_key)
        self.model = os.getenv("CLAUDE_MODEL", "claude-3-opus-20240229")
        
    async def _process_task_internal(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """Process task using Claude API"""
        try:
            content = task.get("content", "")
            context = task.get("context", {})
            task_type = task.get("task_type", "GENERAL")
            
            # Update thinking process
            await self.update_thinking(task["id"], {
                "type": {"icon": "ğŸ¤–", "label": "Claude"},
                "stage": "ã‚¿ã‚¹ã‚¯ã‚’åˆ†æä¸­",
                "steps": [{
                    "description": f"ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—: {task_type}",
                    "detail": f"ãƒ¢ãƒ‡ãƒ«: {self.model}",
                }]
            })
            
            # Build system prompt based on task type
            system_prompt = self._build_system_prompt(task_type, context)
            
            # Build messages for Claude
            messages = []
            
            # Add context messages if available
            if context.get("previous_messages"):
                for msg in context["previous_messages"][-5:]:  # Last 5 messages
                    messages.append({
                        "role": msg.get("role", "user"),
                        "content": msg.get("content", "")
                    })
            
            # Add current message
            messages.append({"role": "user", "content": content})
            
            # Update thinking
            await self.update_thinking(task["id"], {
                "type": {"icon": "ğŸ’­", "label": "ç”Ÿæˆä¸­"},
                "stage": "Claude APIã‚’å‘¼ã³å‡ºã—ä¸­",
                "steps": [{
                    "description": "å¿œç­”ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...",
                    "detail": f"ãƒˆãƒ¼ã‚¯ãƒ³æ•°: ~{len(content.split()) * 1.3:.0f}",
                }]
            })
            
            # Call Claude API with streaming
            response_content = ""
            chunk_count = 0
            
            async with self.client.messages.stream(
                model=self.model,
                messages=messages,
                system=system_prompt,
                max_tokens=2000,
                temperature=0.7,
            ) as stream:
                async for text in stream.text_stream:
                    response_content += text
                    chunk_count += 1
                    
                    # Send streaming update every 10 chunks
                    if chunk_count % 10 == 0:
                        await self.send_streaming_update(task["id"], response_content)
            
            # Final update
            await self.send_streaming_update(task["id"], response_content, is_complete=True)
            
            # Update thinking
            await self.update_thinking(task["id"], {
                "type": {"icon": "âœ…", "label": "å®Œäº†"},
                "stage": "å¿œç­”ç”Ÿæˆå®Œäº†",
                "steps": [{
                    "description": "å¿œç­”ã®ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸ",
                    "detail": f"æ–‡å­—æ•°: {len(response_content)}",
                }]
            })
            
            return {
                "content": response_content,
                "model": self.model,
                "usage": {
                    "prompt_tokens": len(str(messages)) // 4,  # Rough estimate
                    "completion_tokens": len(response_content) // 4,
                },
                "metadata": {
                    "worker_id": self.worker_id,
                    "task_type": task_type,
                }
            }
            
        except Exception as e:
            logger.error(f"Error processing task: {str(e)}")
            await self.update_thinking(task["id"], {
                "type": {"icon": "âŒ", "label": "ã‚¨ãƒ©ãƒ¼"},
                "stage": "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
                "steps": [{
                    "description": f"ã‚¨ãƒ©ãƒ¼: {str(e)}",
                    "detail": "ã‚¿ã‚¹ã‚¯ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
                }]
            })
            raise
    
    def _build_system_prompt(self, task_type: str, context: Dict[str, Any]) -> str:
        """Build system prompt based on task type"""
        base_prompt = "ã‚ãªãŸã¯é«˜åº¦ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®Claudeã§ã™ã€‚"
        
        type_prompts = {
            "CODE_GENERATION": "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã¨ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã«ç‰¹åŒ–ã—ã¦ã„ã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰ã¯æ˜ç¢ºã§ã€åŠ¹ç‡çš„ã§ã€ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã«å¾“ã†ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚ç‰¹ã«ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«æ³¨æ„ã‚’æ‰•ã£ã¦ãã ã•ã„ã€‚",
            "TEXT_GENERATION": "ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ã§æœ‰ç›Šãªãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ç”Ÿæˆã«ç‰¹åŒ–ã—ã¦ã„ã¾ã™ã€‚èª­ã¿ã‚„ã™ãã€é­…åŠ›çš„ãªæ–‡ç« ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚",
            "DOCUMENTATION": "æŠ€è¡“æ–‡æ›¸ã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä½œæˆã«ç‰¹åŒ–ã—ã¦ã„ã¾ã™ã€‚æ˜ç¢ºã§æ§‹é€ åŒ–ã•ã‚ŒãŸã€é–‹ç™ºè€…ã«å„ªã—ã„æ–‡æ›¸ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚",
            "ANALYSIS": "ãƒ‡ãƒ¼ã‚¿åˆ†æã¨æ´å¯Ÿã®æä¾›ã«ç‰¹åŒ–ã—ã¦ã„ã¾ã™ã€‚è«–ç†çš„ã§æ ¹æ‹ ã®ã‚ã‚‹ã€å®Ÿç”¨çš„ãªåˆ†æã‚’è¡Œã£ã¦ãã ã•ã„ã€‚",
            "PR_REVIEW": "ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«ç‰¹åŒ–ã—ã¦ã„ã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰ã®å“è³ªã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€å¯èª­æ€§ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚",
            "GENERAL": "å¹…åºƒã„çŸ¥è­˜ã‚’æ´»ç”¨ã—ã¦ã€æ§˜ã€…ãªè³ªå•ã«ç­”ãˆã¾ã™ã€‚æ­£ç¢ºã§æœ‰ç”¨ãªæƒ…å ±ã‚’æä¾›ã™ã‚‹ã“ã¨ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚"
        }
        
        prompt = base_prompt + " " + type_prompts.get(task_type, type_prompts["GENERAL"])
        
        # Add project context if available
        if context.get("project_name"):
            prompt += f"\n\nç¾åœ¨ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {context['project_name']}"
        if context.get("task_name"):
            prompt += f"\nç¾åœ¨ã®ã‚¿ã‚¹ã‚¯: {context['task_name']}"
        
        # Add language preference
        prompt += "\n\næ—¥æœ¬èªã§å¿œç­”ã—ã¦ãã ã•ã„ã€‚ã‚³ãƒ¼ãƒ‰ã‚„ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãªç”¨èªã¯è‹±èªã®ã¾ã¾ã§æ§‹ã„ã¾ã›ã‚“ã€‚"
        
        return prompt
    
    async def list_models(self) -> List[str]:
        """
        åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚¹ãƒˆã‚’è¿”ã™
        AnthropicãŒå…¬å¼ã«æä¾›ã—ã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆã‚’ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã§è¿”å´
        
        Returns:
            List[str]: åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«IDã®ãƒªã‚¹ãƒˆ
        """
        # Anthropic Claude models (as of 2024)
        return [
            "claude-3-opus-20240229",
            "claude-3-sonnet-20240229",
            "claude-3-haiku-20240307",
            "claude-2.1",
            "claude-2.0",
            "claude-instant-1.2"
        ]

async def main():
    """Main function to run the worker"""
    try:
        worker = ClaudeWorker()
        logger.info(f"Starting Claude Worker: {worker.worker_id}")
        await worker.start()
    except KeyboardInterrupt:
        logger.info("Shutting down worker...")
    except Exception as e:
        logger.error(f"Worker error: {str(e)}")

if __name__ == "__main__":
    asyncio.run(main())