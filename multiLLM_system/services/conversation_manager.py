"""
Conversation Manager - ä¼šè©±ç®¡ç†ã¨è‡ªå‹•è¦ç´„ã‚µãƒ¼ãƒ“ã‚¹
ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨ç‡ã‚’ç›£è¦–ã—ã€å¿…è¦ã«å¿œã˜ã¦LLMã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’åˆ‡ã‚Šæ›¿ãˆ
"""

import asyncio
import logging
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
import json
import tiktoken

logger = logging.getLogger(__name__)


@dataclass
class Message:
    """ä¼šè©±ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"""
    role: str  # user, assistant, system
    content: str
    timestamp: datetime
    tokens: int = 0
    metadata: Optional[Dict] = None


@dataclass
class Conversation:
    """ä¼šè©±ã‚»ãƒƒã‚·ãƒ§ãƒ³"""
    id: str
    user_id: str
    messages: List[Message]
    created_at: datetime
    updated_at: datetime
    total_tokens: int = 0
    max_tokens: int = 128000  # GPT-4ã®å ´åˆ
    llm_instance_id: str = None
    summary: Optional[str] = None
    metadata: Dict = None


class ConversationManager:
    """
    ä¼šè©±ç®¡ç†ã¨è‡ªå‹•è¦ç´„ãƒ»LLMåˆ‡ã‚Šæ›¿ãˆã‚’è¡Œã†ã‚µãƒ¼ãƒ“ã‚¹
    """
    
    def __init__(self, config: Dict, memory_sync_service=None):
        self.config = config
        self.memory_sync = memory_sync_service
        
        # è‡ªå‹•è¦ç´„è¨­å®š
        self.auto_summarize = config.get('autoSummarize', {})
        self.summary_threshold = self.auto_summarize.get('threshold', 0.8)
        self.summary_model = self.auto_summarize.get('summaryModel', 'gpt-3.5-turbo')
        self.summary_max_tokens = self.auto_summarize.get('summaryMaxTokens', 1000)
        
        # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªä¼šè©±
        self.conversations = {}
        
        # ãƒˆãƒ¼ã‚¯ãƒ³ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
        self.tokenizer = None
        self._init_tokenizer()
        
        # LLMãƒ—ãƒ¼ãƒ«ï¼ˆè¤‡æ•°ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç®¡ç†ï¼‰
        self.llm_pool = {}
        self.next_instance_id = 0
    
    def _init_tokenizer(self):
        """ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®åˆæœŸåŒ–"""
        try:
            self.tokenizer = tiktoken.encoding_for_model("gpt-4")
        except Exception as e:
            logger.warning(f"Failed to initialize tokenizer: {e}")
            self.tokenizer = tiktoken.get_encoding("cl100k_base")
    
    def count_tokens(self, text: str) -> int:
        """ãƒ†ã‚­ã‚¹ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ"""
        if not self.tokenizer:
            # ç°¡æ˜“çš„ãªæ¨å®šï¼ˆ1æ–‡å­—â‰’0.25ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰
            return len(text) // 4
        
        return len(self.tokenizer.encode(text))
    
    async def create_conversation(self, user_id: str, metadata: Optional[Dict] = None) -> Conversation:
        """æ–°ã—ã„ä¼šè©±ã‚’ä½œæˆ"""
        conversation_id = f"conv_{user_id}_{datetime.now().strftime('%Y%m%d%H%M%S')}"
        
        conversation = Conversation(
            id=conversation_id,
            user_id=user_id,
            messages=[],
            created_at=datetime.now(),
            updated_at=datetime.now(),
            llm_instance_id=await self._get_or_create_llm_instance(),
            metadata=metadata or {}
        )
        
        self.conversations[conversation_id] = conversation
        logger.info(f"ğŸ“ Created new conversation: {conversation_id}")
        
        return conversation
    
    async def add_message(self, conversation_id: str, role: str, content: str, metadata: Optional[Dict] = None) -> Message:
        """ä¼šè©±ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ """
        conversation = self.conversations.get(conversation_id)
        if not conversation:
            raise ValueError(f"Conversation {conversation_id} not found")
        
        # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¨ˆç®—
        tokens = self.count_tokens(content)
        
        message = Message(
            role=role,
            content=content,
            timestamp=datetime.now(),
            tokens=tokens,
            metadata=metadata
        )
        
        conversation.messages.append(message)
        conversation.total_tokens += tokens
        conversation.updated_at = datetime.now()
        
        # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨ç‡ã‚’ãƒã‚§ãƒƒã‚¯
        usage_ratio = conversation.total_tokens / conversation.max_tokens
        logger.info(f"ğŸ’¬ Added message to {conversation_id}. Token usage: {usage_ratio:.1%}")
        
        # é–¾å€¤ã‚’è¶…ãˆãŸã‚‰è‡ªå‹•å‡¦ç†
        if usage_ratio > self.summary_threshold:
            await self.check_and_rotate(conversation_id)
        
        return message
    
    async def check_and_rotate(self, conversation_id: str) -> Optional[str]:
        """
        ä¼šè©±ã®ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨ç‡ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ã«å¿œã˜ã¦ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
        """
        conversation = self.conversations.get(conversation_id)
        if not conversation:
            return None
        
        usage_ratio = conversation.total_tokens / conversation.max_tokens
        
        if usage_ratio > self.summary_threshold:
            logger.warning(f"âš ï¸ Conversation {conversation_id} reaching token limit: {usage_ratio:.1%}")
            
            # ä¼šè©±ã‚’è¦ç´„
            summary = await self.summarize_conversation(conversation)
            
            # OpenMemoryã«ä¿å­˜
            if self.memory_sync:
                await self.memory_sync.create_conversation_summary(
                    conversation_id,
                    [msg.__dict__ for msg in conversation.messages],
                    {
                        'summary': summary,
                        'total_tokens': conversation.total_tokens,
                        'message_count': len(conversation.messages)
                    }
                )
            
            # æ–°ã—ã„LLMã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
            new_instance_id = await self._rotate_llm_instance(conversation, summary)
            
            logger.info(f"âœ… Rotated conversation {conversation_id} to new instance: {new_instance_id}")
            
            return new_instance_id
        
        return None
    
    async def summarize_conversation(self, conversation: Conversation) -> str:
        """ä¼šè©±ã‚’è¦ç´„"""
        logger.info(f"ğŸ“Š Summarizing conversation {conversation.id}...")
        
        # ä¼šè©±å±¥æ­´ã‚’æ•´å½¢
        conversation_text = self._format_conversation_for_summary(conversation)
        
        # è¦ç´„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        prompt = f"""
ä»¥ä¸‹ã®ä¼šè©±ã‚’è¦ç´„ã—ã¦ãã ã•ã„ã€‚é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã€æ±ºå®šäº‹é …ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ã‚’å«ã‚ã¦ãã ã•ã„ã€‚

ä¼šè©±:
{conversation_text}

è¦ç´„ï¼ˆ{self.summary_max_tokens}ãƒˆãƒ¼ã‚¯ãƒ³ä»¥å†…ï¼‰:
"""
        
        # LLMã§è¦ç´„ç”Ÿæˆï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯é©åˆ‡ãªLLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½¿ç”¨ï¼‰
        summary = await self._generate_summary(prompt)
        
        # ä¼šè©±ã«è¦ç´„ã‚’ä¿å­˜
        conversation.summary = summary
        
        return summary
    
    def _format_conversation_for_summary(self, conversation: Conversation, max_messages: int = 50) -> str:
        """è¦ç´„ç”¨ã«ä¼šè©±ã‚’æ•´å½¢"""
        # æœ€æ–°ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å„ªå…ˆ
        messages = conversation.messages[-max_messages:]
        
        formatted = []
        for msg in messages:
            timestamp = msg.timestamp.strftime("%H:%M:%S")
            formatted.append(f"[{timestamp}] {msg.role}: {msg.content[:200]}...")
        
        return "\n".join(formatted)
    
    async def _generate_summary(self, prompt: str) -> str:
        """è¦ç´„ã‚’ç”Ÿæˆï¼ˆå®Ÿéš›ã®LLMå‘¼ã³å‡ºã—ï¼‰"""
        # ãƒ‡ãƒ¢å®Ÿè£…
        summary = f"""
ä¼šè©±ã®è¦ç´„:
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ä¸»ãªè³ªå•ã¨è¦æ±‚äº‹é …
- æä¾›ã•ã‚ŒãŸè§£æ±ºç­–ã¨ã‚¢ãƒ‰ãƒã‚¤ã‚¹
- æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ 
- é‡è¦ãªæ±ºå®šäº‹é …ã¨åˆæ„å†…å®¹
"""
        return summary.strip()
    
    async def _get_or_create_llm_instance(self) -> str:
        """LLMã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—ã¾ãŸã¯ä½œæˆ"""
        instance_id = f"llm_instance_{self.next_instance_id}"
        self.next_instance_id += 1
        
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç®¡ç†
        self.llm_pool[instance_id] = {
            'created_at': datetime.now(),
            'status': 'active',
            'token_count': 0
        }
        
        return instance_id
    
    async def _rotate_llm_instance(self, conversation: Conversation, summary: str) -> str:
        """æ–°ã—ã„LLMã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã«åˆ‡ã‚Šæ›¿ãˆ"""
        # å¤ã„ä¼šè©±ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        old_messages = conversation.messages.copy()
        conversation.messages.clear()
        conversation.total_tokens = 0
        
        # ã‚µãƒãƒªãƒ¼ã‚’ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã—ã¦è¿½åŠ 
        summary_message = Message(
            role="system",
            content=f"Previous conversation summary:\n{summary}",
            timestamp=datetime.now(),
            tokens=self.count_tokens(summary)
        )
        conversation.messages.append(summary_message)
        conversation.total_tokens = summary_message.tokens
        
        # æ–°ã—ã„ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        new_instance_id = await self._get_or_create_llm_instance()
        conversation.llm_instance_id = new_instance_id
        
        # å¤ã„ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        # ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯é©åˆ‡ã«ãƒªã‚½ãƒ¼ã‚¹ã‚’è§£æ”¾ï¼‰
        
        return new_instance_id
    
    def get_conversation_history(self, conversation_id: str, limit: Optional[int] = None) -> List[Dict]:
        """ä¼šè©±å±¥æ­´ã‚’å–å¾—"""
        conversation = self.conversations.get(conversation_id)
        if not conversation:
            return []
        
        messages = conversation.messages
        if limit:
            messages = messages[-limit:]
        
        return [
            {
                'role': msg.role,
                'content': msg.content,
                'timestamp': msg.timestamp.isoformat(),
                'tokens': msg.tokens
            }
            for msg in messages
        ]
    
    def get_conversation_context(self, conversation_id: str) -> str:
        """LLMã«æ¸¡ã™ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ"""
        conversation = self.conversations.get(conversation_id)
        if not conversation:
            return ""
        
        # ã‚µãƒãƒªãƒ¼ãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚’å«ã‚ã‚‹
        context_parts = []
        
        if conversation.summary:
            context_parts.append(f"[Previous Summary]\n{conversation.summary}\n")
        
        # æœ€è¿‘ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å«ã‚ã‚‹ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã‚’è€ƒæ…®ï¼‰
        recent_messages = []
        token_count = 0
        max_context_tokens = 4000  # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”¨ã®æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°
        
        for msg in reversed(conversation.messages):
            if token_count + msg.tokens > max_context_tokens:
                break
            recent_messages.insert(0, msg)
            token_count += msg.tokens
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ•´å½¢
        for msg in recent_messages:
            context_parts.append(f"{msg.role}: {msg.content}")
        
        return "\n".join(context_parts)
    
    def get_stats(self) -> Dict[str, Any]:
        """çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        active_conversations = [c for c in self.conversations.values() 
                              if (datetime.now() - c.updated_at).total_seconds() < 3600]
        
        return {
            'total_conversations': len(self.conversations),
            'active_conversations': len(active_conversations),
            'total_messages': sum(len(c.messages) for c in self.conversations.values()),
            'average_tokens_per_conversation': sum(c.total_tokens for c in self.conversations.values()) / max(len(self.conversations), 1),
            'llm_instances': len(self.llm_pool)
        }
    
    async def cleanup_old_conversations(self, max_age_hours: int = 24):
        """å¤ã„ä¼šè©±ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        now = datetime.now()
        to_remove = []
        
        for conv_id, conversation in self.conversations.items():
            age = (now - conversation.updated_at).total_seconds() / 3600
            if age > max_age_hours:
                to_remove.append(conv_id)
        
        for conv_id in to_remove:
            # ãƒ¡ãƒ¢ãƒªã«ä¿å­˜ã—ã¦ã‹ã‚‰å‰Šé™¤
            if self.memory_sync:
                conversation = self.conversations[conv_id]
                await self.memory_sync.create_conversation_summary(
                    conv_id,
                    [msg.__dict__ for msg in conversation.messages],
                    {'reason': 'cleanup', 'age_hours': max_age_hours}
                )
            
            del self.conversations[conv_id]
            logger.info(f"ğŸ—‘ï¸ Cleaned up old conversation: {conv_id}")
        
        return len(to_remove)


# ä½¿ç”¨ä¾‹
async def main():
    config = {
        'autoSummarize': {
            'enabled': True,
            'threshold': 0.8,
            'summaryModel': 'gpt-3.5-turbo',
            'summaryMaxTokens': 1000
        }
    }
    
    manager = ConversationManager(config)
    
    # ä¼šè©±ã‚’ä½œæˆ
    conversation = await manager.create_conversation("user123")
    
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
    await manager.add_message(conversation.id, "user", "ã“ã‚“ã«ã¡ã¯ã€Pythonã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„")
    await manager.add_message(conversation.id, "assistant", "ã“ã‚“ã«ã¡ã¯ï¼Pythonã«ã¤ã„ã¦ä½•ã‚’çŸ¥ã‚ŠãŸã„ã§ã™ã‹ï¼Ÿ")
    
    # ä¼šè©±å±¥æ­´ã‚’å–å¾—
    history = manager.get_conversation_history(conversation.id)
    print(f"Conversation history: {json.dumps(history, indent=2, ensure_ascii=False)}")
    
    # çµ±è¨ˆæƒ…å ±
    stats = manager.get_stats()
    print(f"Stats: {json.dumps(stats, indent=2)}")


if __name__ == "__main__":
    asyncio.run(main())