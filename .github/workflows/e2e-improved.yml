name: E2E Tests (Improved)

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    - cron: '0 0 * * *'  # Daily at midnight

env:
  E2E_BASE_URL: ${{ vars.E2E_BASE_URL || 'http://localhost:8000' }}
  E2E_TIMEOUT: 60000
  PLAYWRIGHT_BROWSERS_PATH: ~/.cache/playwright

jobs:
  e2e-test:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest]
        browser: [chromium, firefox, webkit]
        shard: [1, 2, 3]
        
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Get Playwright version
      id: playwright-version
      run: |
        PLAYWRIGHT_VERSION=$(pip show playwright | grep Version | cut -d' ' -f2 || echo "1.45.0")
        echo "version=$PLAYWRIGHT_VERSION" >> $GITHUB_OUTPUT
    
    - name: Cache Playwright browsers
      uses: actions/cache@v3
      with:
        path: ${{ env.PLAYWRIGHT_BROWSERS_PATH }}
        key: playwright-${{ runner.os }}-${{ steps.playwright-version.outputs.version }}
    
    - name: Cache dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: e2e-${{ runner.os }}-${{ hashFiles('requirements*.txt') }}
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y \
          libgtk-3-0 \
          libatspi2.0-0 \
          libxcomposite1 \
          libxdamage1 \
          libxfixes3 \
          libxrandr2 \
          libgbm1 \
          libxkbcommon0 \
          libpango-1.0-0 \
          libcairo2
    
    - name: Install Python dependencies
      run: |
        pip install -r requirements.txt -r requirements-test.txt
        playwright install ${{ matrix.browser }} --with-deps
    
    - name: Prepare test environment
      run: |
        cp .env.example .env.test
        echo "E2E_BROWSER=${{ matrix.browser }}" >> .env.test
        
        # Generate mock data
        python scripts/generate_mock_data.py --e2e
    
    - name: Start application
      run: |
        # Start the application in background
        python -m src.main &
        APP_PID=$!
        echo "APP_PID=$APP_PID" >> $GITHUB_ENV
        
        # Wait for application to be ready
        python - <<EOF
        import time
        import requests
        
        max_attempts = 30
        for i in range(max_attempts):
            try:
                resp = requests.get("${{ env.E2E_BASE_URL }}/health")
                if resp.status_code == 200:
                    print("Application is ready!")
                    break
            except Exception:
                pass
            time.sleep(1)
        else:
            raise Exception("Application failed to start")
        EOF
    
    - name: Run E2E tests
      id: test
      run: |
        pytest tests/e2e \
          --browser=${{ matrix.browser }} \
          --headed=${{ github.event_name == 'pull_request' && 'false' || 'true' }} \
          --video=retain-on-failure \
          --screenshot=only-on-failure \
          --tracing=retain-on-failure \
          --shard=${{ matrix.shard }}/3 \
          --junit-xml=junit-${{ matrix.browser }}-${{ matrix.shard }}.xml
    
    - name: Stop application
      if: always()
      run: |
        if [ -n "$APP_PID" ]; then
          kill $APP_PID || true
        fi
    
    - name: Upload test artifacts
      if: failure()
      uses: actions/upload-artifact@v4
      with:
        name: e2e-artifacts-${{ matrix.browser }}-${{ matrix.shard }}
        path: |
          test-results/
          screenshots/
          videos/
          traces/
    
    - name: Upload test results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: e2e-results-${{ matrix.browser }}-${{ matrix.shard }}
        path: junit-*.xml

  e2e-report:
    needs: e2e-test
    if: always()
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Download test results
      uses: actions/download-artifact@v4
      with:
        pattern: e2e-results-*
        merge-multiple: true
    
    - name: Merge test results
      run: |
        pip install junitparser
        python - <<EOF
        from junitparser import JUnitXml
        import glob
        
        # Merge all JUnit files
        combined = JUnitXml()
        for file in glob.glob('junit-*.xml'):
            suite = JUnitXml.fromfile(file)
            for testsuite in suite:
                combined.add_testsuite(testsuite)
        
        combined.write('e2e-combined-results.xml')
        EOF
    
    - name: Generate HTML report
      run: |
        pip install pytest-html-reporter
        python -m pytest_html_reporter.cli \
          --junit-xml e2e-combined-results.xml \
          --output-path e2e-report.html
    
    - name: Upload final report
      uses: actions/upload-artifact@v4
      with:
        name: e2e-final-report
        path: |
          e2e-report.html
          e2e-combined-results.xml
    
    - name: Comment on PR
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const report = fs.readFileSync('e2e-combined-results.xml', 'utf8');
          
          // Parse results
          const failures = (report.match(/failures="(\d+)"/g) || [])
            .map(m => parseInt(m.match(/\d+/)[0]))
            .reduce((a, b) => a + b, 0);
          
          const errors = (report.match(/errors="(\d+)"/g) || [])
            .map(m => parseInt(m.match(/\d+/)[0]))
            .reduce((a, b) => a + b, 0);
          
          const tests = (report.match(/tests="(\d+)"/g) || [])
            .map(m => parseInt(m.match(/\d+/)[0]))
            .reduce((a, b) => a + b, 0);
          
          const status = failures + errors === 0 ? '✅' : '❌';
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: `### E2E Test Results ${status}
            
            - **Total Tests**: ${tests}
            - **Failures**: ${failures}
            - **Errors**: ${errors}
            
            [View Full Report](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})`
          })

  visual-regression:
    needs: e2e-test
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Download screenshots
      uses: actions/download-artifact@v4
      with:
        pattern: e2e-artifacts-*
        merge-multiple: true
    
    - name: Compare screenshots
      run: |
        pip install scikit-image numpy
        python scripts/visual_regression.py \
          --baseline screenshots/baseline \
          --current screenshots/current \
          --output screenshots/diff
    
    - name: Upload visual diff
      if: failure()
      uses: actions/upload-artifact@v4
      with:
        name: visual-regression-diff
        path: screenshots/diff/