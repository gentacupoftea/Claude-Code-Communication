version: '3.8'

services:
  # AI分析サービス
  ai-analytics:
    build:
      context: .
      dockerfile: Dockerfile.ai
    environment:
      - NODE_ENV=production
      - TENSORFLOW_CPU_THREADS=4
      - TF_CPP_MIN_LOG_LEVEL=2
    volumes:
      - ./src/ai:/app/src/ai
      - ./models:/app/models
      - ai-cache:/app/cache
    ports:
      - "3003:3003"
    depends_on:
      - redis
      - postgres
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G

  # 機械学習モデルトレーニングサービス
  ml-training:
    build:
      context: .
      dockerfile: Dockerfile.ml
    environment:
      - PYTHON_ENV=production
      - CUDA_VISIBLE_DEVICES=-1  # CPU only
    volumes:
      - ./src/ai:/app/src/ai
      - ./models:/app/models
      - ./data:/app/data
      - training-logs:/app/logs
    depends_on:
      - postgres
    restart: "no"
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G

  # データパイプラインサービス
  data-pipeline:
    build:
      context: .
      dockerfile: Dockerfile
    command: ["node", "dist/src/ai/pipeline/worker.js"]
    environment:
      - NODE_ENV=production
      - PIPELINE_MODE=continuous
      - BATCH_SIZE=1000
    volumes:
      - ./src/ai/pipeline:/app/src/ai/pipeline
      - pipeline-data:/app/data
    depends_on:
      - redis
      - postgres
      - kafka
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 2G

  # Jupyter Notebook（開発・実験用）
  jupyter:
    image: jupyter/tensorflow-notebook:latest
    ports:
      - "8888:8888"
    volumes:
      - ./notebooks:/home/jovyan/work
      - ./data:/home/jovyan/data
      - ./models:/home/jovyan/models
    environment:
      - JUPYTER_ENABLE_LAB=yes
    profiles:
      - development

  # Redis（キャッシュとキュー）
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes
    restart: unless-stopped

  # PostgreSQL（メトリクスとモデルメタデータ）
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=shopify_ai
      - POSTGRES_USER=ai_user
      - POSTGRES_PASSWORD=${DB_PASSWORD:-changeme}
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./sql/init.sql:/docker-entrypoint-initdb.d/init.sql
    restart: unless-stopped

  # Kafka（イベントストリーミング）
  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
    volumes:
      - kafka-data:/var/lib/kafka/data
    restart: unless-stopped

  # Zookeeper（Kafka用）
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    ports:
      - "2181:2181"
    environment:
      - ZOOKEEPER_CLIENT_PORT=2181
      - ZOOKEEPER_TICK_TIME=2000
    volumes:
      - zookeeper-data:/var/lib/zookeeper
    restart: unless-stopped

  # MLflow（モデル管理）
  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    ports:
      - "5000:5000"
    volumes:
      - ./mlruns:/mlruns
      - ./models:/models
    environment:
      - MLFLOW_BACKEND_STORE_URI=postgresql://ai_user:${DB_PASSWORD:-changeme}@postgres/shopify_ai
      - MLFLOW_DEFAULT_ARTIFACT_ROOT=/models
    command: >
      mlflow server
      --host 0.0.0.0
      --backend-store-uri postgresql://ai_user:${DB_PASSWORD:-changeme}@postgres/shopify_ai
      --default-artifact-root /models
    depends_on:
      - postgres
    profiles:
      - ml-ops

  # Grafana（モニタリング）
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/datasources:/etc/grafana/provisioning/datasources
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    depends_on:
      - prometheus
    restart: unless-stopped
    profiles:
      - monitoring

  # Prometheus（メトリクス収集）
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    restart: unless-stopped
    profiles:
      - monitoring

volumes:
  ai-cache:
  training-logs:
  pipeline-data:
  redis-data:
  postgres-data:
  kafka-data:
  zookeeper-data:
  grafana-data:
  prometheus-data:

networks:
  default:
    name: shopify-ai-network