#!/usr/bin/env python3
"""
OptimizedCacheManager - è² è·ãƒ†ã‚¹ãƒˆãƒ„ãƒ¼ãƒ«
ç›®çš„ï¼šå®Ÿéš›ã®ä½¿ç”¨æ¡ä»¶ã«è¿‘ã„è² è·ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã€æ€§èƒ½é™ç•Œã®æ¤œè¨¼
"""
import argparse
import json
import multiprocessing
import os
import random
import string
import sys
import threading
import time
import urllib.request
import urllib.error
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
import matplotlib
matplotlib.use('Agg')  # GUIãªã—ã§å®Ÿè¡Œã™ã‚‹ãŸã‚ã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰è¨­å®š
import matplotlib.pyplot as plt
import numpy as np

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ‘ã‚¹
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
SCRIPTS_DIR = os.path.dirname(SCRIPT_DIR)
PROJECT_ROOT = os.path.dirname(SCRIPTS_DIR)
LOAD_TEST_DIR = os.path.join(SCRIPT_DIR, "load_tests")

# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
os.makedirs(LOAD_TEST_DIR, exist_ok=True)

# OptimizedCacheManagerã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    sys.path.append(PROJECT_ROOT)
    from src.api.cache_client import CacheClient
except ImportError:
    print("ã‚¨ãƒ©ãƒ¼: CacheClientãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    print(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ: {PROJECT_ROOT}")
    sys.exit(1)

def print_section(title):
    """ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¡¨ç¤º"""
    print("\n" + "=" * 80)
    print(f"  {title}")
    print("=" * 80)

def generate_random_string(size):
    """ãƒ©ãƒ³ãƒ€ãƒ ãªæ–‡å­—åˆ—ã‚’ç”Ÿæˆ
    
    Args:
        size: æ–‡å­—åˆ—ã®é•·ã•
        
    Returns:
        str: ãƒ©ãƒ³ãƒ€ãƒ æ–‡å­—åˆ—
    """
    return ''.join(random.choice(string.ascii_letters + string.digits) for _ in range(size))

def generate_random_data(size_min, size_max):
    """æŒ‡å®šç¯„å›²ã®ã‚µã‚¤ã‚ºã‚’ã‚‚ã¤ãƒ©ãƒ³ãƒ€ãƒ ãªãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
    
    Args:
        size_min: æœ€å°ã‚µã‚¤ã‚ºï¼ˆãƒã‚¤ãƒˆï¼‰
        size_max: æœ€å¤§ã‚µã‚¤ã‚ºï¼ˆãƒã‚¤ãƒˆï¼‰
        
    Returns:
        dict: ãƒ©ãƒ³ãƒ€ãƒ ãƒ‡ãƒ¼ã‚¿
    """
    # ã‚µã‚¤ã‚ºã‚’æŒ‡å®šç¯„å›²å†…ã§ãƒ©ãƒ³ãƒ€ãƒ ã«æ±ºå®š
    size = random.randint(size_min, size_max)
    
    # ãƒ‡ãƒ¼ã‚¿ã®ç¨®é¡ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠ
    data_type = random.choice(['string', 'dict', 'list', 'mixed'])
    
    if data_type == 'string':
        return generate_random_string(size)
    elif data_type == 'dict':
        # è¾æ›¸ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
        items = {}
        bytes_used = 0
        while bytes_used < size:
            key = generate_random_string(random.randint(5, 15))
            value = generate_random_string(random.randint(10, 100))
            items[key] = value
            bytes_used += len(key) + len(value)
        return items
    elif data_type == 'list':
        # ãƒªã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
        items = []
        bytes_used = 0
        while bytes_used < size:
            item = generate_random_string(random.randint(10, 100))
            items.append(item)
            bytes_used += len(item)
        return items
    else:  # mixed
        # è¤‡åˆãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
        result = {
            'id': random.randint(1, 10000),
            'name': generate_random_string(random.randint(10, 20)),
            'attributes': {},
            'tags': []
        }
        
        # å±æ€§ã®è¿½åŠ 
        attr_count = random.randint(5, 20)
        for _ in range(attr_count):
            key = generate_random_string(random.randint(5, 15))
            value = generate_random_string(random.randint(10, 50))
            result['attributes'][key] = value
        
        # ã‚¿ã‚°ã®è¿½åŠ 
        tag_count = random.randint(3, 10)
        for _ in range(tag_count):
            result['tags'].append(generate_random_string(random.randint(5, 15)))
        
        return result

class LoadTestWorker:
    """è² è·ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œã‚’æ‹…å½“ã™ã‚‹ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, worker_id, api_url, test_config):
        """åˆæœŸåŒ–
        
        Args:
            worker_id: ãƒ¯ãƒ¼ã‚«ãƒ¼ID
            api_url: ã‚­ãƒ£ãƒƒã‚·ãƒ¥APIã®URL
            test_config: ãƒ†ã‚¹ãƒˆè¨­å®š
        """
        self.worker_id = worker_id
        self.api_url = api_url
        self.config = test_config
        self.client = CacheClient(api_url)
        
        # ãƒ†ã‚¹ãƒˆçµæœã‚’ä¿å­˜ã™ã‚‹ãƒ‡ã‚£ã‚¯ã‚·ãƒ§ãƒŠãƒª
        self.results = {
            "worker_id": worker_id,
            "operations": 0,
            "successes": 0,
            "failures": 0,
            "start_time": None,
            "end_time": None,
            "duration": 0,
            "set_times": [],
            "get_times": [],
            "invalidate_times": [],
            "errors": []
        }
    
    def _generate_key(self):
        """ãƒ†ã‚¹ãƒˆç”¨ã®ã‚­ãƒ¼ã‚’ç”Ÿæˆ"""
        prefix = self.config.get('key_prefix', 'loadtest')
        # ã‚­ãƒ¼è¡çªã‚’é˜²ããŸã‚ã«ãƒ¯ãƒ¼ã‚«ãƒ¼IDã¨ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å«ã‚ã‚‹
        return f"{prefix}:worker{self.worker_id}:{int(time.time() * 1000)}:{random.randint(1, 1000000)}"
    
    def _record_time(self, operation, time_ms):
        """æ“ä½œæ™‚é–“ã‚’è¨˜éŒ²"""
        if operation == 'set':
            self.results["set_times"].append(time_ms)
        elif operation == 'get':
            self.results["get_times"].append(time_ms)
        elif operation == 'invalidate':
            self.results["invalidate_times"].append(time_ms)
    
    def _record_error(self, operation, error):
        """ã‚¨ãƒ©ãƒ¼ã‚’è¨˜éŒ²"""
        self.results["errors"].append({
            "operation": operation,
            "error": str(error),
            "timestamp": datetime.now().isoformat()
        })
        self.results["failures"] += 1
    
    def run_test(self):
        """è² è·ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        self.results["start_time"] = datetime.now().isoformat()
        
        test_duration = self.config.get('duration', 60)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ60ç§’
        operations_per_second = self.config.get('operations_per_second', 10)
        operation_interval = 1.0 / operations_per_second if operations_per_second > 0 else 0
        
        data_size_min = self.config.get('data_size_min', 100)
        data_size_max = self.config.get('data_size_max', 10000)
        ttl = self.config.get('ttl', 60)
        
        # æ“ä½œã®ç¢ºç‡
        op_weights = self.config.get('operation_weights', {'set': 0.3, 'get': 0.6, 'invalidate': 0.1})
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ã—ãŸã‚­ãƒ¼ã‚’è¿½è·¡
        cached_keys = []
        max_cached_keys = 1000  # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’åˆ¶é™
        
        start_time = time.time()
        end_time = start_time + test_duration
        
        # æ“ä½œã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
        self.results["operations"] = 0
        self.results["successes"] = 0
        
        try:
            while time.time() < end_time:
                operation_start = time.time()
                
                # ãƒ©ãƒ³ãƒ€ãƒ ãªæ“ä½œã®é¸æŠ
                operation = random.choices(
                    ['set', 'get', 'invalidate'],
                    weights=[op_weights.get('set', 0.3), op_weights.get('get', 0.6), op_weights.get('invalidate', 0.1)]
                )[0]
                
                try:
                    if operation == 'set':
                        # SETæ“ä½œ
                        key = self._generate_key()
                        value = generate_random_data(data_size_min, data_size_max)
                        
                        start = time.time()
                        success = self.client.set(key, value, ttl)
                        elapsed = (time.time() - start) * 1000  # ãƒŸãƒªç§’ã«å¤‰æ›
                        
                        if success:
                            cached_keys.append(key)
                            self.results["successes"] += 1
                            self._record_time('set', elapsed)
                            
                            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ãƒªã‚¹ãƒˆã®ã‚µã‚¤ã‚ºã‚’åˆ¶é™
                            if len(cached_keys) > max_cached_keys:
                                cached_keys = cached_keys[-max_cached_keys:]
                    
                    elif operation == 'get':
                        # GETæ“ä½œ
                        if cached_keys:
                            # æ—¢å­˜ã®ã‚­ãƒ¼ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠ
                            key = random.choice(cached_keys)
                            
                            start = time.time()
                            value = self.client.get(key)
                            elapsed = (time.time() - start) * 1000  # ãƒŸãƒªç§’ã«å¤‰æ›
                            
                            if value is not None:
                                self.results["successes"] += 1
                                self._record_time('get', elapsed)
                        else:
                            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ãŒãªã„å ´åˆã¯SETæ“ä½œã‚’å®Ÿè¡Œ
                            key = self._generate_key()
                            value = generate_random_data(data_size_min, data_size_max)
                            
                            start = time.time()
                            success = self.client.set(key, value, ttl)
                            elapsed = (time.time() - start) * 1000  # ãƒŸãƒªç§’ã«å¤‰æ›
                            
                            if success:
                                cached_keys.append(key)
                                self.results["successes"] += 1
                                self._record_time('set', elapsed)
                    
                    elif operation == 'invalidate':
                        # INVALIDATEæ“ä½œ
                        if cached_keys:
                            # æ—¢å­˜ã®ã‚­ãƒ¼ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠã—ã¦å‰Šé™¤
                            key = random.choice(cached_keys)
                            
                            start = time.time()
                            success = self.client.invalidate(key)
                            elapsed = (time.time() - start) * 1000  # ãƒŸãƒªç§’ã«å¤‰æ›
                            
                            if success:
                                if key in cached_keys:
                                    cached_keys.remove(key)
                                self.results["successes"] += 1
                                self._record_time('invalidate', elapsed)
                
                except Exception as e:
                    self._record_error(operation, e)
                
                self.results["operations"] += 1
                
                # æ¬¡ã®æ“ä½œã¾ã§ã‚¹ãƒªãƒ¼ãƒ—ï¼ˆä¸€å®šã®ãƒ¬ãƒ¼ãƒˆã‚’ç¶­æŒã™ã‚‹ãŸã‚ï¼‰
                time_taken = time.time() - operation_start
                sleep_time = max(0, operation_interval - time_taken)
                if sleep_time > 0:
                    time.sleep(sleep_time)
        
        except KeyboardInterrupt:
            print(f"ãƒ¯ãƒ¼ã‚«ãƒ¼ {self.worker_id}: ãƒ†ã‚¹ãƒˆãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        
        # çµæœã‚’è¨ˆç®—
        self.results["end_time"] = datetime.now().isoformat()
        end_timestamp = time.time()
        self.results["duration"] = end_timestamp - start_time
        
        return self.results

class LoadTester:
    """OptimizedCacheManagerã®è² è·ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config=None):
        """åˆæœŸåŒ–
        
        Args:
            config: ãƒ†ã‚¹ãƒˆè¨­å®š
        """
        self.config = config or {}
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.results = {}
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
        self.api_url = self.config.get('api_url', 'http://localhost:8000')
        self.workers = self.config.get('workers', 4)
        self.test_id = self.config.get('test_id', self.timestamp)
        
        # çµæœã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        self.results = {
            "test_id": self.test_id,
            "timestamp": self.timestamp,
            "config": self.config,
            "worker_results": [],
            "summary": {}
        }
    
    def run_test(self):
        """è² è·ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        print_section("è² è·ãƒ†ã‚¹ãƒˆé–‹å§‹")
        print(f"API URL: {self.api_url}")
        print(f"ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°: {self.workers}")
        print(f"ãƒ†ã‚¹ãƒˆæœŸé–“: {self.config.get('duration', 60)}ç§’")
        print(f"æ“ä½œ/ç§’/ãƒ¯ãƒ¼ã‚«ãƒ¼: {self.config.get('operations_per_second', 10)}")
        
        # ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ã®ãƒªã‚¹ãƒˆ
        worker_processes = []
        
        # å‰å‡¦ç†ï¼šAPIã‚µãƒ¼ãƒãƒ¼ãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
        try:
            client = CacheClient(self.api_url)
            health = client.healthcheck()
            if health.get("status") == "healthy":
                print(f"APIã‚µãƒ¼ãƒãƒ¼ã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™: {health}")
            else:
                print(f"è­¦å‘Š: APIã‚µãƒ¼ãƒãƒ¼ã®çŠ¶æ…‹ãŒä¸æ˜ã§ã™: {health}")
        except Exception as e:
            print(f"ã‚¨ãƒ©ãƒ¼: APIã‚µãƒ¼ãƒãƒ¼ã¸ã®æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return False
        
        # ãƒ†ã‚¹ãƒˆå‰ã®çµ±è¨ˆæƒ…å ±ã®å–å¾—
        try:
            before_stats = client.get_stats()
            print("ãƒ†ã‚¹ãƒˆå‰ã®çµ±è¨ˆæƒ…å ±:")
            print(f"  ãƒ’ãƒƒãƒˆç‡: {before_stats.get('hit_rate', 0) * 100:.2f}%")
            print(f"  ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {before_stats.get('memory_usage_mb', 0):.2f} MB ({before_stats.get('memory_usage_percent', 0):.2f}%)")
            
            self.results["before_stats"] = before_stats
        except Exception as e:
            print(f"è­¦å‘Š: ãƒ†ã‚¹ãƒˆå‰ã®çµ±è¨ˆæƒ…å ±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        
        print("\nãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        start_time = time.time()
        
        # ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹ã§ä¸¦åˆ—å®Ÿè¡Œ
        with ThreadPoolExecutor(max_workers=self.workers) as executor:
            futures = []
            
            for i in range(self.workers):
                worker = LoadTestWorker(i, self.api_url, self.config)
                futures.append(executor.submit(worker.run_test))
            
            # é€²æ—è¡¨ç¤º
            test_duration = self.config.get('duration', 60)
            while time.time() - start_time < test_duration:
                elapsed = int(time.time() - start_time)
                remaining = max(0, test_duration - elapsed)
                print(f"\rçµŒéæ™‚é–“: {elapsed}ç§’ / æ®‹ã‚Šæ™‚é–“: {remaining}ç§’", end="")
                time.sleep(1)
            
            print("\n\nã™ã¹ã¦ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã®å®Œäº†ã‚’å¾…æ©Ÿä¸­...")
            
            # çµæœã®åé›†
            for future in futures:
                try:
                    worker_result = future.result()
                    self.results["worker_results"].append(worker_result)
                except Exception as e:
                    print(f"ãƒ¯ãƒ¼ã‚«ãƒ¼ã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        
        # ãƒ†ã‚¹ãƒˆå¾Œã®çµ±è¨ˆæƒ…å ±ã®å–å¾—
        try:
            after_stats = client.get_stats()
            print("\nãƒ†ã‚¹ãƒˆå¾Œã®çµ±è¨ˆæƒ…å ±:")
            print(f"  ãƒ’ãƒƒãƒˆç‡: {after_stats.get('hit_rate', 0) * 100:.2f}%")
            print(f"  ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {after_stats.get('memory_usage_mb', 0):.2f} MB ({after_stats.get('memory_usage_percent', 0):.2f}%)")
            
            self.results["after_stats"] = after_stats
        except Exception as e:
            print(f"è­¦å‘Š: ãƒ†ã‚¹ãƒˆå¾Œã®çµ±è¨ˆæƒ…å ±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        
        # çµæœã®é›†è¨ˆã¨åˆ†æ
        self.analyze_results()
        
        # çµæœã‚’ä¿å­˜
        self.save_results()
        
        # ã‚°ãƒ©ãƒ•ã®ç”Ÿæˆ
        self.generate_graphs()
        
        return True
    
    def analyze_results(self):
        """ãƒ†ã‚¹ãƒˆçµæœã‚’åˆ†æ"""
        print_section("çµæœåˆ†æ")
        
        summary = {
            "total_workers": len(self.results["worker_results"]),
            "total_duration": 0,
            "total_operations": 0,
            "total_successes": 0,
            "total_failures": 0,
            "success_rate": 0,
            "operations_per_second": 0,
            "avg_set_time_ms": 0,
            "avg_get_time_ms": 0,
            "avg_invalidate_time_ms": 0,
            "p95_set_time_ms": 0,
            "p95_get_time_ms": 0,
            "p95_invalidate_time_ms": 0
        }
        
        # å„ãƒ¯ãƒ¼ã‚«ãƒ¼ã®çµæœã‚’é›†è¨ˆ
        all_set_times = []
        all_get_times = []
        all_invalidate_times = []
        all_errors = []
        
        for worker_result in self.results["worker_results"]:
            summary["total_operations"] += worker_result.get("operations", 0)
            summary["total_successes"] += worker_result.get("successes", 0)
            summary["total_failures"] += worker_result.get("failures", 0)
            summary["total_duration"] += worker_result.get("duration", 0)
            
            all_set_times.extend(worker_result.get("set_times", []))
            all_get_times.extend(worker_result.get("get_times", []))
            all_invalidate_times.extend(worker_result.get("invalidate_times", []))
            all_errors.extend(worker_result.get("errors", []))
        
        # å¹³å‡å€¤ã‚’è¨ˆç®—
        if summary["total_workers"] > 0:
            summary["total_duration"] /= summary["total_workers"]
        
        if summary["total_operations"] > 0:
            summary["success_rate"] = (summary["total_successes"] / summary["total_operations"]) * 100
        
        if summary["total_duration"] > 0:
            summary["operations_per_second"] = summary["total_operations"] / summary["total_duration"]
        
        # æ“ä½œæ™‚é–“ã®çµ±è¨ˆ
        if all_set_times:
            summary["avg_set_time_ms"] = sum(all_set_times) / len(all_set_times)
            summary["p95_set_time_ms"] = np.percentile(all_set_times, 95)
        
        if all_get_times:
            summary["avg_get_time_ms"] = sum(all_get_times) / len(all_get_times)
            summary["p95_get_time_ms"] = np.percentile(all_get_times, 95)
        
        if all_invalidate_times:
            summary["avg_invalidate_time_ms"] = sum(all_invalidate_times) / len(all_invalidate_times)
            summary["p95_invalidate_time_ms"] = np.percentile(all_invalidate_times, 95)
        
        # ã‚¨ãƒ©ãƒ¼ç‡
        summary["error_rate"] = (summary["total_failures"] / max(1, summary["total_operations"])) * 100
        
        # ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¨ãƒ¡ãƒ¢ãƒªã®å¤‰åŒ–ï¼ˆçµ±è¨ˆæƒ…å ±ãŒã‚ã‚‹å ´åˆï¼‰
        if "before_stats" in self.results and "after_stats" in self.results:
            before = self.results["before_stats"]
            after = self.results["after_stats"]
            
            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å¤‰åŒ–
            if "memory_usage_mb" in before and "memory_usage_mb" in after:
                before_memory = before["memory_usage_mb"]
                after_memory = after["memory_usage_mb"]
                memory_change = after_memory - before_memory
                memory_change_pct = (memory_change / max(0.1, before_memory)) * 100
                
                summary["memory_usage_before_mb"] = before_memory
                summary["memory_usage_after_mb"] = after_memory
                summary["memory_usage_change_mb"] = memory_change
                summary["memory_usage_change_percent"] = memory_change_pct
            
            # ãƒ’ãƒƒãƒˆç‡ã®å¤‰åŒ–
            if "hit_rate" in before and "hit_rate" in after:
                before_hit_rate = before["hit_rate"] * 100
                after_hit_rate = after["hit_rate"] * 100
                hit_rate_change = after_hit_rate - before_hit_rate
                
                summary["hit_rate_before"] = before_hit_rate
                summary["hit_rate_after"] = after_hit_rate
                summary["hit_rate_change"] = hit_rate_change
        
        # ã‚¨ãƒ©ãƒ¼ã‚µãƒãƒªãƒ¼
        error_summary = {}
        for error in all_errors:
            error_message = error.get("error", "")
            if error_message in error_summary:
                error_summary[error_message] += 1
            else:
                error_summary[error_message] = 1
        
        summary["error_summary"] = error_summary
        
        # çµæœã‚’è¡¨ç¤º
        print(f"ç·æ“ä½œæ•°: {summary['total_operations']}")
        print(f"æˆåŠŸæ•°: {summary['total_successes']}")
        print(f"å¤±æ•—æ•°: {summary['total_failures']}")
        print(f"æˆåŠŸç‡: {summary['success_rate']:.2f}%")
        print(f"1ç§’ã‚ãŸã‚Šã®æ“ä½œæ•°: {summary['operations_per_second']:.2f}")
        print(f"å¹³å‡SETæ™‚é–“: {summary['avg_set_time_ms']:.3f} ms")
        print(f"å¹³å‡GETæ™‚é–“: {summary['avg_get_time_ms']:.3f} ms")
        print(f"å¹³å‡INVALIDATEæ™‚é–“: {summary['avg_invalidate_time_ms']:.3f} ms")
        print(f"P95 SETæ™‚é–“: {summary['p95_set_time_ms']:.3f} ms")
        print(f"P95 GETæ™‚é–“: {summary['p95_get_time_ms']:.3f} ms")
        print(f"P95 INVALIDATEæ™‚é–“: {summary['p95_invalidate_time_ms']:.3f} ms")
        
        if "memory_usage_change_mb" in summary:
            print(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å¤‰åŒ–: {summary['memory_usage_change_mb']:.2f} MB ({summary['memory_usage_change_percent']:+.2f}%)")
        
        if "hit_rate_change" in summary:
            print(f"ãƒ’ãƒƒãƒˆç‡ã®å¤‰åŒ–: {summary['hit_rate_change']:+.2f}%")
        
        if error_summary:
            print("\nä¸»ãªã‚¨ãƒ©ãƒ¼:")
            for error, count in sorted(error_summary.items(), key=lambda x: x[1], reverse=True)[:5]:
                print(f"  {error}: {count}å›")
        
        # ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®è©•ä¾¡
        if summary["operations_per_second"] >= 1000:
            print("\nâ­ å„ªã‚ŒãŸã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: æ¯ç§’1000æ“ä½œä»¥ä¸Š")
        elif summary["operations_per_second"] >= 500:
            print("\nğŸ‘ è‰¯å¥½ãªã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: æ¯ç§’500æ“ä½œä»¥ä¸Š")
        elif summary["operations_per_second"] >= 100:
            print("\nâœ“ æ™®é€šã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: æ¯ç§’100æ“ä½œä»¥ä¸Š")
        else:
            print("\nâš  æ³¨æ„: ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆãŒä½ã„ï¼ˆæ¯ç§’100æ“ä½œæœªæº€ï¼‰")
        
        # ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã®è©•ä¾¡
        if summary["avg_get_time_ms"] <= 1.0:
            print("â­ å„ªã‚ŒãŸGETãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: 1msä»¥ä¸‹")
        elif summary["avg_get_time_ms"] <= 5.0:
            print("ğŸ‘ è‰¯å¥½ãªGETãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: 5msä»¥ä¸‹")
        elif summary["avg_get_time_ms"] <= 20.0:
            print("âœ“ æ™®é€šã®GETãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: 20msä»¥ä¸‹")
        else:
            print("âš  æ³¨æ„: GETãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãŒé«˜ã„ï¼ˆ20msè¶…ï¼‰")
        
        # ã‚¨ãƒ©ãƒ¼ç‡ã®è©•ä¾¡
        if summary["error_rate"] <= 0.1:
            print("â­ å„ªã‚ŒãŸå®‰å®šæ€§: ã‚¨ãƒ©ãƒ¼ç‡0.1%ä»¥ä¸‹")
        elif summary["error_rate"] <= 1.0:
            print("ğŸ‘ è‰¯å¥½ãªå®‰å®šæ€§: ã‚¨ãƒ©ãƒ¼ç‡1%ä»¥ä¸‹")
        elif summary["error_rate"] <= 5.0:
            print("âœ“ æ™®é€šã®å®‰å®šæ€§: ã‚¨ãƒ©ãƒ¼ç‡5%ä»¥ä¸‹")
        else:
            print("âš  æ³¨æ„: ã‚¨ãƒ©ãƒ¼ç‡ãŒé«˜ã„ï¼ˆ5%è¶…ï¼‰")
        
        # ãƒ’ãƒƒãƒˆç‡ã®è©•ä¾¡
        if "hit_rate_after" in summary and summary["hit_rate_after"] >= 80:
            print("â­ å„ªã‚ŒãŸãƒ’ãƒƒãƒˆç‡: 80%ä»¥ä¸Š")
        elif "hit_rate_after" in summary and summary["hit_rate_after"] >= 60:
            print("ğŸ‘ è‰¯å¥½ãªãƒ’ãƒƒãƒˆç‡: 60%ä»¥ä¸Š")
        elif "hit_rate_after" in summary and summary["hit_rate_after"] >= 40:
            print("âœ“ æ™®é€šã®ãƒ’ãƒƒãƒˆç‡: 40%ä»¥ä¸Š")
        elif "hit_rate_after" in summary:
            print("âš  æ³¨æ„: ãƒ’ãƒƒãƒˆç‡ãŒä½ã„ï¼ˆ40%æœªæº€ï¼‰")
        
        # ç·åˆè©•ä¾¡
        score_components = []
        
        # ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚¹ã‚³ã‚¢ï¼ˆ0-100ï¼‰
        throughput_score = min(100, summary["operations_per_second"] / 10)
        score_components.append(throughput_score)
        
        # ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã‚¹ã‚³ã‚¢ï¼ˆ0-100ï¼‰
        if summary["avg_get_time_ms"] > 0:
            latency_score = min(100, 100 / summary["avg_get_time_ms"])
        else:
            latency_score = 100
        score_components.append(latency_score)
        
        # å®‰å®šæ€§ã‚¹ã‚³ã‚¢ï¼ˆ0-100ï¼‰
        stability_score = 100 - min(100, summary["error_rate"] * 10)
        score_components.append(stability_score)
        
        # ãƒ’ãƒƒãƒˆç‡ã‚¹ã‚³ã‚¢ï¼ˆ0-100ï¼‰
        if "hit_rate_after" in summary:
            hit_rate_score = summary["hit_rate_after"]
            score_components.append(hit_rate_score)
        
        # ç·åˆã‚¹ã‚³ã‚¢ã®è¨ˆç®—
        if score_components:
            overall_score = sum(score_components) / len(score_components)
            summary["overall_score"] = overall_score
            
            # å®šæ€§çš„è©•ä¾¡
            if overall_score >= 90:
                summary["rating"] = "å„ªç§€"
            elif overall_score >= 75:
                summary["rating"] = "è‰¯å¥½"
            elif overall_score >= 60:
                summary["rating"] = "æ™®é€š"
            else:
                summary["rating"] = "è¦æ”¹å–„"
            
            print(f"\nç·åˆã‚¹ã‚³ã‚¢: {overall_score:.2f}/100 ({summary['rating']})")
        
        # ã‚µãƒãƒªãƒ¼ã‚’çµæœã«ä¿å­˜
        self.results["summary"] = summary
    
    def save_results(self):
        """ãƒ†ã‚¹ãƒˆçµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        print_section("çµæœã®ä¿å­˜")
        
        # JSONå½¢å¼ã§ä¿å­˜
        filename = f"loadtest_results_{self.timestamp}.json"
        filepath = os.path.join(LOAD_TEST_DIR, filename)
        
        with open(filepath, "w") as f:
            json.dump(self.results, f, indent=2)
        
        print(f"ãƒ†ã‚¹ãƒˆçµæœã‚’JSONã§ä¿å­˜ã—ã¾ã—ãŸ: {filepath}")
        
        # Markdownå½¢å¼ã§ã‚‚ä¿å­˜
        md_filename = f"loadtest_results_{self.timestamp}.md"
        md_filepath = os.path.join(LOAD_TEST_DIR, md_filename)
        
        with open(md_filepath, "w") as f:
            f.write(self.generate_markdown_report())
        
        print(f"ãƒ†ã‚¹ãƒˆçµæœã‚’Markdownã§ä¿å­˜ã—ã¾ã—ãŸ: {md_filepath}")
        
        return filepath, md_filepath
    
    def generate_markdown_report(self):
        """Markdownãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        summary = self.results["summary"]
        
        md = []
        md.append("# OptimizedCacheManager è² è·ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆ")
        md.append("")
        md.append(f"å®Ÿè¡Œæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        md.append(f"ãƒ†ã‚¹ãƒˆID: {self.results['test_id']}")
        md.append("")
        
        # ãƒ†ã‚¹ãƒˆè¨­å®š
        md.append("## ãƒ†ã‚¹ãƒˆè¨­å®š")
        md.append("")
        md.append(f"- API URL: {self.config.get('api_url', 'http://localhost:8000')}")
        md.append(f"- ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°: {self.config.get('workers', 4)}")
        md.append(f"- ãƒ†ã‚¹ãƒˆæœŸé–“: {self.config.get('duration', 60)}ç§’")
        md.append(f"- æ“ä½œ/ç§’/ãƒ¯ãƒ¼ã‚«ãƒ¼: {self.config.get('operations_per_second', 10)}")
        md.append(f"- ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºç¯„å›²: {self.config.get('data_size_min', 100)} - {self.config.get('data_size_max', 10000)}ãƒã‚¤ãƒˆ")
        md.append(f"- TTL: {self.config.get('ttl', 60)}ç§’")
        
        # æ“ä½œã‚¦ã‚§ã‚¤ãƒˆ
        op_weights = self.config.get('operation_weights', {'set': 0.3, 'get': 0.6, 'invalidate': 0.1})
        md.append(f"- æ“ä½œåˆ†å¸ƒ: SET {op_weights.get('set', 0.3) * 100}%, GET {op_weights.get('get', 0.6) * 100}%, INVALIDATE {op_weights.get('invalidate', 0.1) * 100}%")
        md.append("")
        
        # çµæœã‚µãƒãƒªãƒ¼
        md.append("## çµæœã‚µãƒãƒªãƒ¼")
        md.append("")
        if "overall_score" in summary:
            md.append(f"**ç·åˆã‚¹ã‚³ã‚¢: {summary['overall_score']:.2f}/100 ({summary['rating']})**")
            md.append("")
        
        # æ“ä½œçµ±è¨ˆ
        md.append("### æ“ä½œçµ±è¨ˆ")
        md.append("")
        md.append(f"- ç·æ“ä½œæ•°: {summary['total_operations']}")
        md.append(f"- æˆåŠŸæ“ä½œæ•°: {summary['total_successes']}")
        md.append(f"- å¤±æ•—æ“ä½œæ•°: {summary['total_failures']}")
        md.append(f"- æˆåŠŸç‡: {summary['success_rate']:.2f}%")
        md.append(f"- 1ç§’ã‚ãŸã‚Šã®æ“ä½œæ•°: {summary['operations_per_second']:.2f}")
        md.append("")
        
        # ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·çµ±è¨ˆ
        md.append("### ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·çµ±è¨ˆ")
        md.append("")
        md.append("| æ“ä½œ | å¹³å‡ (ms) | P95 (ms) |")
        md.append("|------|-----------|----------|")
        md.append(f"| SET | {summary['avg_set_time_ms']:.3f} | {summary['p95_set_time_ms']:.3f} |")
        md.append(f"| GET | {summary['avg_get_time_ms']:.3f} | {summary['p95_get_time_ms']:.3f} |")
        md.append(f"| INVALIDATE | {summary['avg_invalidate_time_ms']:.3f} | {summary['p95_invalidate_time_ms']:.3f} |")
        md.append("")
        
        # ãƒ¡ãƒ¢ãƒªã¨ãƒ’ãƒƒãƒˆç‡ã®å¤‰åŒ–
        if "memory_usage_change_mb" in summary or "hit_rate_change" in summary:
            md.append("### ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®çŠ¶æ…‹å¤‰åŒ–")
            md.append("")
            
            if "memory_usage_change_mb" in summary:
                md.append(f"- ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {summary['memory_usage_before_mb']:.2f} MB â†’ {summary['memory_usage_after_mb']:.2f} MB ({summary['memory_usage_change_percent']:+.2f}%)")
            
            if "hit_rate_change" in summary:
                md.append(f"- ãƒ’ãƒƒãƒˆç‡: {summary['hit_rate_before']:.2f}% â†’ {summary['hit_rate_after']:.2f}% ({summary['hit_rate_change']:+.2f}%)")
            
            md.append("")
        
        # ã‚¨ãƒ©ãƒ¼çµ±è¨ˆ
        if "error_summary" in summary and summary["error_summary"]:
            md.append("### ã‚¨ãƒ©ãƒ¼çµ±è¨ˆ")
            md.append("")
            md.append(f"- ã‚¨ãƒ©ãƒ¼ç‡: {summary['error_rate']:.2f}%")
            md.append("- ä¸»ãªã‚¨ãƒ©ãƒ¼:")
            
            for error, count in sorted(summary["error_summary"].items(), key=lambda x: x[1], reverse=True)[:5]:
                md.append(f"  - {error}: {count}å›")
            
            md.append("")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡
        md.append("### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡")
        md.append("")
        
        # ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆè©•ä¾¡
        if summary["operations_per_second"] >= 1000:
            md.append("- â­ **å„ªã‚ŒãŸã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ**: æ¯ç§’1000æ“ä½œä»¥ä¸Š")
        elif summary["operations_per_second"] >= 500:
            md.append("- ğŸ‘ **è‰¯å¥½ãªã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ**: æ¯ç§’500æ“ä½œä»¥ä¸Š")
        elif summary["operations_per_second"] >= 100:
            md.append("- âœ“ **æ™®é€šã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ**: æ¯ç§’100æ“ä½œä»¥ä¸Š")
        else:
            md.append("- âš  **æ³¨æ„**: ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆãŒä½ã„ï¼ˆæ¯ç§’100æ“ä½œæœªæº€ï¼‰")
        
        # ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·è©•ä¾¡
        if summary["avg_get_time_ms"] <= 1.0:
            md.append("- â­ **å„ªã‚ŒãŸGETãƒ¬ã‚¤ãƒ†ãƒ³ã‚·**: 1msä»¥ä¸‹")
        elif summary["avg_get_time_ms"] <= 5.0:
            md.append("- ğŸ‘ **è‰¯å¥½ãªGETãƒ¬ã‚¤ãƒ†ãƒ³ã‚·**: 5msä»¥ä¸‹")
        elif summary["avg_get_time_ms"] <= 20.0:
            md.append("- âœ“ **æ™®é€šã®GETãƒ¬ã‚¤ãƒ†ãƒ³ã‚·**: 20msä»¥ä¸‹")
        else:
            md.append("- âš  **æ³¨æ„**: GETãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãŒé«˜ã„ï¼ˆ20msè¶…ï¼‰")
        
        # ã‚¨ãƒ©ãƒ¼ç‡è©•ä¾¡
        if summary["error_rate"] <= 0.1:
            md.append("- â­ **å„ªã‚ŒãŸå®‰å®šæ€§**: ã‚¨ãƒ©ãƒ¼ç‡0.1%ä»¥ä¸‹")
        elif summary["error_rate"] <= 1.0:
            md.append("- ğŸ‘ **è‰¯å¥½ãªå®‰å®šæ€§**: ã‚¨ãƒ©ãƒ¼ç‡1%ä»¥ä¸‹")
        elif summary["error_rate"] <= 5.0:
            md.append("- âœ“ **æ™®é€šã®å®‰å®šæ€§**: ã‚¨ãƒ©ãƒ¼ç‡5%ä»¥ä¸‹")
        else:
            md.append("- âš  **æ³¨æ„**: ã‚¨ãƒ©ãƒ¼ç‡ãŒé«˜ã„ï¼ˆ5%è¶…ï¼‰")
        
        # ãƒ’ãƒƒãƒˆç‡è©•ä¾¡
        if "hit_rate_after" in summary:
            if summary["hit_rate_after"] >= 80:
                md.append("- â­ **å„ªã‚ŒãŸãƒ’ãƒƒãƒˆç‡**: 80%ä»¥ä¸Š")
            elif summary["hit_rate_after"] >= 60:
                md.append("- ğŸ‘ **è‰¯å¥½ãªãƒ’ãƒƒãƒˆç‡**: 60%ä»¥ä¸Š")
            elif summary["hit_rate_after"] >= 40:
                md.append("- âœ“ **æ™®é€šã®ãƒ’ãƒƒãƒˆç‡**: 40%ä»¥ä¸Š")
            else:
                md.append("- âš  **æ³¨æ„**: ãƒ’ãƒƒãƒˆç‡ãŒä½ã„ï¼ˆ40%æœªæº€ï¼‰")
        
        md.append("")
        
        # ã‚°ãƒ©ãƒ•å‚ç…§
        md.append("## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚°ãƒ©ãƒ•")
        md.append("")
        md.append("ä»¥ä¸‹ã®ã‚°ãƒ©ãƒ•ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸ:")
        md.append("")
        md.append(f"- [æ“ä½œãƒ¬ãƒ¼ãƒˆ](./loadtest_graphs_{self.timestamp}/operation_rate.png)")
        md.append(f"- [ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·åˆ†å¸ƒ](./loadtest_graphs_{self.timestamp}/latency_distribution.png)")
        md.append(f"- [ç´¯ç©æ“ä½œæ•°](./loadtest_graphs_{self.timestamp}/cumulative_operations.png)")
        md.append(f"- [çŠ¶æ…‹å¤‰åŒ–](./loadtest_graphs_{self.timestamp}/cache_state_change.png)")
        md.append("")
        
        return "\n".join(md)
    
    def generate_graphs(self):
        """çµæœã«åŸºã¥ã„ã¦ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ"""
        print_section("ã‚°ãƒ©ãƒ•ã®ç”Ÿæˆ")
        
        # ã‚°ãƒ©ãƒ•ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        graphs_dir = os.path.join(LOAD_TEST_DIR, f"loadtest_graphs_{self.timestamp}")
        os.makedirs(graphs_dir, exist_ok=True)
        
        # 1. æ“ä½œãƒ¬ãƒ¼ãƒˆã®ã‚°ãƒ©ãƒ•
        self._generate_operation_rate_graph(graphs_dir)
        
        # 2. ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·åˆ†å¸ƒã®ã‚°ãƒ©ãƒ•
        self._generate_latency_distribution_graph(graphs_dir)
        
        # 3. ç´¯ç©æ“ä½œæ•°ã®ã‚°ãƒ©ãƒ•
        self._generate_cumulative_operations_graph(graphs_dir)
        
        # 4. ã‚­ãƒ£ãƒƒã‚·ãƒ¥çŠ¶æ…‹å¤‰åŒ–ã®ã‚°ãƒ©ãƒ•
        self._generate_cache_state_change_graph(graphs_dir)
        
        print(f"ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {graphs_dir}")
        return graphs_dir
    
    def _generate_operation_rate_graph(self, graphs_dir):
        """æ“ä½œãƒ¬ãƒ¼ãƒˆã®ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ"""
        summary = self.results["summary"]
        worker_results = self.results["worker_results"]
        
        if not worker_results:
            return
        
        plt.figure(figsize=(10, 6))
        
        # ãƒ¯ãƒ¼ã‚«ãƒ¼ã”ã¨ã®æ“ä½œãƒ¬ãƒ¼ãƒˆ
        worker_ids = []
        ops_per_sec = []
        
        for result in worker_results:
            worker_id = result.get("worker_id", "unknown")
            operations = result.get("operations", 0)
            duration = result.get("duration", 1)  # 0é™¤ç®—é˜²æ­¢
            
            rate = operations / duration
            
            worker_ids.append(f"Worker {worker_id}")
            ops_per_sec.append(rate)
        
        # å…¨ä½“ã®æ“ä½œãƒ¬ãƒ¼ãƒˆ
        worker_ids.append("å…¨ä½“")
        ops_per_sec.append(summary.get("operations_per_second", 0))
        
        # ã‚°ãƒ©ãƒ•ã®æç”»
        plt.bar(worker_ids, ops_per_sec, color='skyblue')
        plt.axhline(y=summary.get("operations_per_second", 0), color='r', linestyle='--', label='å¹³å‡')
        
        plt.xlabel('ãƒ¯ãƒ¼ã‚«ãƒ¼')
        plt.ylabel('æ“ä½œ/ç§’')
        plt.title('ãƒ¯ãƒ¼ã‚«ãƒ¼ã”ã¨ã®æ“ä½œãƒ¬ãƒ¼ãƒˆ')
        plt.legend()
        plt.grid(axis='y', linestyle='--', alpha=0.7)
        
        # Yè»¸ã®æœ€å¤§å€¤ã‚’èª¿æ•´
        plt.ylim(0, max(ops_per_sec) * 1.1)
        
        # å€¤ã®ãƒ©ãƒ™ãƒ«ã‚’è¿½åŠ 
        for i, v in enumerate(ops_per_sec):
            plt.text(i, v + max(ops_per_sec) * 0.02, f'{v:.1f}', ha='center')
        
        plt.tight_layout()
        plt.savefig(os.path.join(graphs_dir, "operation_rate.png"))
        plt.close()
    
    def _generate_latency_distribution_graph(self, graphs_dir):
        """ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·åˆ†å¸ƒã®ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ"""
        worker_results = self.results["worker_results"]
        
        if not worker_results:
            return
        
        # ã™ã¹ã¦ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã‹ã‚‰æ“ä½œæ™‚é–“ã‚’åé›†
        all_set_times = []
        all_get_times = []
        all_invalidate_times = []
        
        for result in worker_results:
            all_set_times.extend(result.get("set_times", []))
            all_get_times.extend(result.get("get_times", []))
            all_invalidate_times.extend(result.get("invalidate_times", []))
        
        plt.figure(figsize=(10, 6))
        
        # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã®æç”»
        if all_set_times:
            plt.hist(all_set_times, bins=30, alpha=0.5, label='SET', color='blue')
        
        if all_get_times:
            plt.hist(all_get_times, bins=30, alpha=0.5, label='GET', color='green')
        
        if all_invalidate_times:
            plt.hist(all_invalidate_times, bins=30, alpha=0.5, label='INVALIDATE', color='red')
        
        plt.xlabel('ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· (ms)')
        plt.ylabel('é »åº¦')
        plt.title('æ“ä½œåˆ¥ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·åˆ†å¸ƒ')
        plt.legend()
        plt.grid(linestyle='--', alpha=0.7)
        
        # Xè»¸ã®ç¯„å›²ã‚’èª¿æ•´ï¼ˆå¤–ã‚Œå€¤ã‚’é™¤å¤–ï¼‰
        max_times = []
        if all_set_times:
            max_times.append(np.percentile(all_set_times, 99))
        if all_get_times:
            max_times.append(np.percentile(all_get_times, 99))
        if all_invalidate_times:
            max_times.append(np.percentile(all_invalidate_times, 99))
        
        if max_times:
            plt.xlim(0, max(max_times) * 1.1)
        
        plt.tight_layout()
        plt.savefig(os.path.join(graphs_dir, "latency_distribution.png"))
        plt.close()
    
    def _generate_cumulative_operations_graph(self, graphs_dir):
        """ç´¯ç©æ“ä½œæ•°ã®ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ"""
        summary = self.results["summary"]
        
        plt.figure(figsize=(10, 6))
        
        # æ“ä½œç·æ•°
        total_ops = summary.get("total_operations", 0)
        success_ops = summary.get("total_successes", 0)
        failure_ops = summary.get("total_failures", 0)
        
        # æ“ä½œã‚¿ã‚¤ãƒ—ã®å†…è¨³ã‚’æ¨å®šï¼ˆæ­£ç¢ºãªæ•°å­—ãŒãªã‘ã‚Œã°æ¨å®šï¼‰
        operation_weights = self.config.get('operation_weights', {'set': 0.3, 'get': 0.6, 'invalidate': 0.1})
        set_ops = int(total_ops * operation_weights.get('set', 0.3))
        get_ops = int(total_ops * operation_weights.get('get', 0.6))
        invalidate_ops = total_ops - set_ops - get_ops
        
        # å·¦å´ã®ã‚°ãƒ©ãƒ•ï¼šæ“ä½œã‚¿ã‚¤ãƒ—ã®å†…è¨³
        plt.subplot(1, 2, 1)
        labels = ['SET', 'GET', 'INVALIDATE']
        sizes = [set_ops, get_ops, invalidate_ops]
        colors = ['#66b3ff', '#99ff99', '#ffcc99']
        
        plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)
        plt.axis('equal')
        plt.title('æ“ä½œã‚¿ã‚¤ãƒ—ã®åˆ†å¸ƒ')
        
        # å³å´ã®ã‚°ãƒ©ãƒ•ï¼šæˆåŠŸãƒ»å¤±æ•—ã®å†…è¨³
        plt.subplot(1, 2, 2)
        labels = ['æˆåŠŸ', 'å¤±æ•—']
        sizes = [success_ops, failure_ops]
        colors = ['#66b3ff', '#ff9999']
        
        plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)
        plt.axis('equal')
        plt.title('æ“ä½œçµæœã®åˆ†å¸ƒ')
        
        plt.suptitle('ç´¯ç©æ“ä½œçµ±è¨ˆ')
        plt.tight_layout()
        plt.savefig(os.path.join(graphs_dir, "cumulative_operations.png"))
        plt.close()
    
    def _generate_cache_state_change_graph(self, graphs_dir):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥çŠ¶æ…‹å¤‰åŒ–ã®ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ"""
        summary = self.results["summary"]
        
        # 'before_stats'ã¨'after_stats'ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if "memory_usage_before_mb" not in summary or "hit_rate_before" not in summary:
            return
        
        plt.figure(figsize=(12, 5))
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å¤‰åŒ–
        plt.subplot(1, 2, 1)
        memory_before = summary.get("memory_usage_before_mb", 0)
        memory_after = summary.get("memory_usage_after_mb", 0)
        
        plt.bar(['ãƒ†ã‚¹ãƒˆå‰', 'ãƒ†ã‚¹ãƒˆå¾Œ'], [memory_before, memory_after], color=['lightblue', 'blue'])
        plt.ylabel('ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ (MB)')
        plt.title('ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å¤‰åŒ–')
        plt.grid(axis='y', linestyle='--', alpha=0.7)
        
        # å€¤ã®ãƒ©ãƒ™ãƒ«ã‚’è¿½åŠ 
        plt.text(0, memory_before, f'{memory_before:.2f}', ha='center', va='bottom')
        plt.text(1, memory_after, f'{memory_after:.2f}', ha='center', va='bottom')
        
        # ãƒ¡ãƒ¢ãƒªå¤‰åŒ–ç‡ã‚’è¡¨ç¤º
        memory_change_pct = summary.get("memory_usage_change_percent", 0)
        plt.figtext(0.3, 0.01, f'å¤‰åŒ–ç‡: {memory_change_pct:+.2f}%', ha='center')
        
        # ãƒ’ãƒƒãƒˆç‡ã®å¤‰åŒ–
        plt.subplot(1, 2, 2)
        hit_rate_before = summary.get("hit_rate_before", 0)
        hit_rate_after = summary.get("hit_rate_after", 0)
        
        plt.bar(['ãƒ†ã‚¹ãƒˆå‰', 'ãƒ†ã‚¹ãƒˆå¾Œ'], [hit_rate_before, hit_rate_after], color=['lightgreen', 'green'])
        plt.ylabel('ãƒ’ãƒƒãƒˆç‡ (%)')
        plt.title('ãƒ’ãƒƒãƒˆç‡ã®å¤‰åŒ–')
        plt.grid(axis='y', linestyle='--', alpha=0.7)
        
        # Yè»¸ã‚’0-100ã«è¨­å®š
        plt.ylim(0, 100)
        
        # å€¤ã®ãƒ©ãƒ™ãƒ«ã‚’è¿½åŠ 
        plt.text(0, hit_rate_before, f'{hit_rate_before:.2f}', ha='center', va='bottom')
        plt.text(1, hit_rate_after, f'{hit_rate_after:.2f}', ha='center', va='bottom')
        
        # ãƒ’ãƒƒãƒˆç‡å¤‰åŒ–ã‚’è¡¨ç¤º
        hit_rate_change = summary.get("hit_rate_change", 0)
        plt.figtext(0.7, 0.01, f'å¤‰åŒ–ç‡: {hit_rate_change:+.2f}%', ha='center')
        
        plt.tight_layout()
        plt.savefig(os.path.join(graphs_dir, "cache_state_change.png"))
        plt.close()

def main():
    parser = argparse.ArgumentParser(description="OptimizedCacheManagerã®è² è·ãƒ†ã‚¹ãƒˆ")
    parser.add_argument("--url", type=str, default="http://localhost:8000", help="ã‚­ãƒ£ãƒƒã‚·ãƒ¥APIã®URL (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: http://localhost:8000)")
    parser.add_argument("--workers", type=int, default=4, help="ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼ã®æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 4)")
    parser.add_argument("--duration", type=int, default=60, help="ãƒ†ã‚¹ãƒˆæœŸé–“ï¼ˆç§’ï¼‰ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 60)")
    parser.add_argument("--ops-per-sec", type=int, default=10, help="1ç§’ã‚ãŸã‚Šã®æ“ä½œæ•°/ãƒ¯ãƒ¼ã‚«ãƒ¼ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10)")
    parser.add_argument("--min-size", type=int, default=100, help="æœ€å°ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºï¼ˆãƒã‚¤ãƒˆï¼‰ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 100)")
    parser.add_argument("--max-size", type=int, default=10000, help="æœ€å¤§ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºï¼ˆãƒã‚¤ãƒˆï¼‰ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10000)")
    parser.add_argument("--ttl", type=int, default=60, help="TTLï¼ˆç§’ï¼‰ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 60)")
    parser.add_argument("--set-weight", type=float, default=0.3, help="SETæ“ä½œã®æ¯”ç‡ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.3)")
    parser.add_argument("--get-weight", type=float, default=0.6, help="GETæ“ä½œã®æ¯”ç‡ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.6)")
    parser.add_argument("--invalidate-weight", type=float, default=0.1, help="INVALIDATEæ“ä½œã®æ¯”ç‡ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.1)")
    parser.add_argument("--test-id", type=str, help="ãƒ†ã‚¹ãƒˆã®ä¸€æ„è­˜åˆ¥å­")
    
    args = parser.parse_args()
    
    # æ“ä½œã‚¦ã‚§ã‚¤ãƒˆã®æ­£è¦åŒ–
    total_weight = args.set_weight + args.get_weight + args.invalidate_weight
    set_weight = args.set_weight / total_weight
    get_weight = args.get_weight / total_weight
    invalidate_weight = args.invalidate_weight / total_weight
    
    # ãƒ†ã‚¹ãƒˆè¨­å®š
    config = {
        "api_url": args.url,
        "workers": args.workers,
        "duration": args.duration,
        "operations_per_second": args.ops_per_sec,
        "data_size_min": args.min_size,
        "data_size_max": args.max_size,
        "ttl": args.ttl,
        "operation_weights": {
            "set": set_weight,
            "get": get_weight,
            "invalidate": invalidate_weight
        },
        "test_id": args.test_id
    }
    
    # è² è·ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    tester = LoadTester(config)
    success = tester.run_test()
    
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()